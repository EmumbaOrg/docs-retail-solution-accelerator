{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Before You Begin","text":"<p>This guide serves as both a solution accelerator and a learning tool for developers who want to build AI-powered e-commerce personalization solutions using Azure Database for PostgreSQL, Azure AI Services, and multi-agent systems powered by LlamaIndex. The AgenticShop Guide provides a hands-on experience to help you jumpstart your own projects and gain practical skills in Gen AI applications.</p> <p>To complete this guide, you will need the following:</p> <ul> <li> Requires using your own Azure subscription \u2013 you can get one for free</li> <li> Requires you to provision the infrastructure in your Azure subscription \u2013 we provide detailed instructions and Bicep deployment scripts</li> <li> Requires using your own computer</li> <li> Requires you to setup a development environment on your computer \u2013 we provide detailed instructions</li> <li> Basic familiarity with Python \u2013 helpful but not mandatory</li> </ul>"},{"location":"01-Introduction/","title":"Introduction","text":"<p>Welcome to the AgenticShop Guide \u2013 a detailed reference guide built around a prototype e-commerce store that demonstrates how Generative AI can be used to personalize shopping experiences through a multi-agent architecture.</p> <p>In this guide, you will:</p> <ul> <li>Learn how to structure and implement multi-agent workflows using LlamaIndex</li> <li>Explore in-database AI capabilities using the Azure AI extension on Azure Database for PostgreSQL \u2013 Flexible Server</li> <li>Interact with product data, reviews, and user profiles using graph queries powered by Apache AGE</li> <li>Use pg_diskann for fast and efficient vector search in PostgreSQL</li> </ul> <p>You\u2019ll work with a curated sample dataset that includes:</p> <ul> <li>A catalog of products and their features</li> <li>User profiles and product reviews</li> </ul> <p>Throughout the guide, you\u2019ll discover how GenAI-based systems work and how they can be applied in real-world scenarios.</p> <p>You can find the complete source code here: github.com/Azure-Samples/postgres-agentic-shop</p>"},{"location":"01-Introduction/#learning-objectives","title":"Learning Objectives","text":"<p>This solution accelerator will equip you with the skills to enhance your applications with AI capabilities using Azure Database for PostgreSQL and Azure AI Services. You\u2019ll gain hands-on experience integrating advanced AI-powered extraction into the data ingestion process.</p> <p>By incorporating Apache AGE, you\u2019ll learn how to model and store product-review relationships as a graph\u2014capturing features, sentiments, and user interactions. Using Azure OpenAI, you\u2019ll extract structured product attributes and sentiment insights, enabling rich graph construction and support for complex search queries like \u201cheadphones with positive reviews about noise cancellation\u201d that include both vector and Cypher queries.</p> <p>You\u2019ll explore pg_diskann to perform fast and scalable vector similarity searches within PostgreSQL, enabling real-time product and review retrieval.</p> <p>The guide also demonstrates how to design and orchestrate multi-agent workflows using LlamaIndex, leveraging strategies such as tool-using agents, Text-to-SQL, and Retrieval-Augmented Generation (RAG). You\u2019ll also learn how to incorporate persistent agent memory using Mem0, allowing agents to retain user-specific context across interactions.</p> <p>To ensure transparency and debuggability, the solution includes end-to-end observability using Phoenix (by Arize), enabling tracing, span-level inspection, and performance monitoring of each agent\u2019s execution within the workflow.</p> <p>By completing this guide, you will learn how to:</p> <ul> <li>Leverage Azure OpenAI to extract product features and sentiment for downstream graph and search applications</li> <li>Embed Generative AI capabilities directly into PostgreSQL workflows using the Azure AI extension</li> <li>Perform fast, scalable vector similarity searches using pg_diskann, integrated with LlamaIndex</li> <li>Design and orchestrate multi-agent systems using LlamaIndex, with persistent memory via Mem0 and observability via Phoenix Arize</li> <li>Host the solution using Azure Container Apps to simulate a real-world production deployment</li> <li>Use the Azure Developer CLI and templates to provision and deploy applications consistently across teams</li> <li>Use Apache AGE along with the Azure AI extension to:</li> <li>Model graph representations of products, reviews, features, and sentiments</li> <li>Run complex Cypher queries to find products based on how users talk about specific features     (e.g., \u201cHeadphones with positive reviews about noise cancellation\u201d)</li> </ul>"},{"location":"01-Introduction/#learning-resources","title":"Learning Resources","text":"<ol> <li>Azure Database for PostgreSQL \u2013 Flexible Server | Overview</li> <li>Generative AI with Azure Database for PostgreSQL \u2013 Flexible Server | Overview</li> <li>Azure AI extension for PostgreSQL | How to integrate Azure AI</li> <li>Azure AI Foundry | Documentation \u00b7 Architecture \u00b7 SDKs \u00b7 Evaluation</li> <li>Azure Container Apps | Azure Container Apps \u00b7 Deploy from code</li> <li>Responsible AI | Overview \u00b7 With AI Services \u00b7 Azure AI Content Safety</li> <li>pg_diskann | Fast vector similarity search</li> <li>Apache AGE | Graph extension for PostgreSQL</li> </ol>"},{"location":"01-Introduction/01-App-Scenario/","title":"1.1 The App Scenario","text":""},{"location":"01-Introduction/01-App-Scenario/#personalizing-e-commerce-with-genai-and-multi-agent","title":"Personalizing e-commerce with GenAI and Multi-Agent","text":"<p>In the e-commerce space, delivering a personalized shopping experience has become essential to retaining users and increasing conversion. However, most personalization systems are rule-based or rely on shallow behavioral tracking. These approaches struggle to adapt in real-time to user preferences and product attributes derived from unstructured data such as reviews.</p> <p>The AgenticShop accelerator presents a solution that combines Generative AI, multi-agent orchestration, and in-database intelligence to provide personalized and responsive product discovery experiences.</p> <p>This solution uses a curated electronics dataset\u2014including products, reviews, and user profiles\u2014to simulate real-world personalization scenarios. The system allows users to perform intelligent product searches, analyze reviews for sentiment and features, and update their personalization profile\u2014all in a seamless experience driven by AI agents.</p> <p>The backend is built using Azure Database for PostgreSQL \u2013 Flexible Server, enhanced with:</p> <ul> <li>The pg_diskann extension for high-performance vector search</li> <li>The azure_ai extension for in-database NLP tasks like sentiment and key phrase extraction</li> <li>The Apache AGE extension for modeling product\u2013review\u2013feature relationships as a graph</li> </ul> <p>Multi-agent workflows powered by LlamaIndex handle complex tasks such as routing queries, analyzing reviews, and updating user preferences with persistent memory (via Mem0). The system includes observability and tracing using Phoenix by ArizeAI for full transparency into agent behavior and performance.</p>"},{"location":"01-Introduction/01-App-Scenario/#agentic-query-routing-with-a-smart-search-box","title":"Agentic Query Routing with a Smart Search Box","text":"<p>In addition to personalized workflows, AgenticShop features a unified search interface powered by agents and tools, capable of interpreting user queries in multiple intelligent ways.</p> <p>Behind this single input box, an Agent equipped with three tools dynamically selects the appropriate strategy based on the user\u2019s intent. This enables:</p> <ul> <li> <p>Product-Specific Query Handling   For queries about the currently viewed product (e.g., \"Show critical reviews about durability\"), the agent detects context and regenerates the personalized content accordingly.</p> </li> <li> <p>Standard Vector Search   For product lookups or general discovery queries (e.g., \"Wireless earbuds\"), a pg_diskann-based vector search retrieves the most semantically relevant results.</p> </li> <li> <p>Sentiment-Aware Search   For queries like \"Headphones with great noise cancellation\", the agent combines vector search with in-database sentiment analysis and feature extraction using azure_ai, then optionally filters or reranks results based on extracted review insights.</p> </li> </ul> <p>This intelligent routing architecture allows users to interact naturally with the system, while the agents ensure their intent is correctly interpreted and processed.</p>"},{"location":"01-Introduction/02-App-Architecture/","title":"1.2 App Architecture","text":"<p>The application architecture for AgenticShop is designed to showcase how modern AI-powered applications can be modular, observable, and scalable. This section highlights the core components of the application and how they interact with each other using a combination of frontend/backend technologies and Azure cloud services.</p> <p>At the heart of the system is a multi-agent workflow engine built on top of LlamaIndex. It integrates seamlessly with AI models, vector stores, and memory systems to deliver personalized product experiences based on user interactions.</p>"},{"location":"01-Introduction/02-App-Architecture/#technologies-and-azure-services-used","title":"Technologies and Azure Services Used","text":"<p>This solution leverages a decoupled architecture built on the following components:</p>"},{"location":"01-Introduction/02-App-Architecture/#frontend","title":"Frontend","text":"<ul> <li>React (SPA): A responsive and dynamic single-page application running in the browser.</li> <li>Hosted as an Azure Container App.</li> </ul>"},{"location":"01-Introduction/02-App-Architecture/#backend","title":"Backend","text":"<ul> <li>FastAPI: High-performance Python web framework handling API logic.</li> <li>Azure Container Apps: Hosts both frontend and backend components.</li> <li>Azure Key Vault: Securely stores and retrieves database credentials and secrets.</li> <li>Azure OpenAI: Provides GPT-4o for agent reasoning and personalization.</li> <li>Apache AGE (PostgreSQL Extension): Enables graph queries using Cypher syntax.</li> <li>Azure AI (PostgreSQL Extension): Used for in-database embedding generation and summarization.</li> </ul>"},{"location":"01-Introduction/02-App-Architecture/#observability","title":"Observability","text":"<ul> <li>Phoenix by Arize: Observability tool that captures and visualizes LLM traces and workflows. Integrated directly into the backend app.</li> </ul>"},{"location":"01-Introduction/02-App-Architecture/#data-store","title":"Data Store","text":"<ul> <li>Azure Database for PostgreSQL Flexible Server:</li> <li>Stores products, features, reviews, and user memories.</li> <li>Hosts <code>mem0_chatstore</code> table for memory.</li> <li>Powers AI embeddings, sentiment insights, and graph creation.</li> </ul>"},{"location":"01-Introduction/02-App-Architecture/#app-architecture-diagram","title":"App Architecture Diagram","text":"<p>The following diagram illustrates how these services work together to deliver a seamless AI-powered experience:</p> <p></p> <p>Users interact with the system via a web browser. Their queries are routed through the backend where multi-agent workflows are invoked. Data and memory are retrieved from PostgreSQL, augmented with OpenAI reasoning, and the results are streamed back to the frontend. All workflow activity is traceable via Phoenix for debugging and evaluation.</p> <p>This architecture demonstrates how you can combine modern AI tools and cloud-native services to build rich, interactive, and intelligent applications.</p>"},{"location":"01-Introduction/03-Azure-Cost/","title":"1.3 Azure Cost Estimate","text":"<p>The Microsoft Azure resources you deploy will be provisioned within your Azure Subscription. You are responsible for the cost of those services. The cost of the solution will vary depending on the Azure region selected and deployment options you choose.</p> <p>The Setup section of this guide will tell you how to choose the deployment options.</p> <p>Review the estimated costs of deployed resources.</p> <p>Here's a breakdown of the estimated costs of Azure resources deployed for this solution:</p> Service Name Cost per day ($) Azure Flexible server for PostgreSQL ~4.31 Azure Container Registry ~0.167 Azure Keyvault ~0.18 Azure Container Apps ~4.57 Azure OpenAI Service Pay-as-you-go <p>To summarize the estimated monthly cost:</p> <ul> <li>Per day cost for Azure deployment: ~$9.227 excluding OpenAI models costs</li> <li>Per day cost for local deployment: ~$4.31 excluding OpenAI models costs</li> </ul> <p>The above costs are only estimates.</p> <p>The costs provided here are estimates based on running the solution accelerator using the provided configuration and are intended to provide general guidance about the costs associated with running the solution accelerator. Depending on deployment options, region selection, and requests generated, individual costs will vary.</p>"},{"location":"01-Introduction/04-Data-Structures/","title":"1.4 Backend Data Structures","text":"<p>This section provides an overview of the core database schema and data artifacts used in the AgenticShop backend. It highlights key tables and fields that enable AI-powered personalization, semantic search, review analysis. It also explains how these components are leveraged by backend services and Azure AI integrations.</p>"},{"location":"01-Introduction/04-Data-Structures/#understanding-the-table-schema","title":"Understanding the Table Schema","text":"<p>AgenticShop processes user profiles, product catalogs, product variants, customer reviews, product features, personalized content, and chat interactions using a structured PostgreSQL schema. Below is an overview of the key tables and their roles:</p>"},{"location":"01-Introduction/04-Data-Structures/#core-tables-their-purpose","title":"Core Tables &amp; Their Purpose","text":"Table Description <code>users</code> Stores user profiles, including preferences (hobbies, lifestyle), demographics, and search history. Used for personalization. <code>products</code> Contains core product catalog information, specifications (JSONB), pricing, and descriptions. <code>product_images</code> Stores URLs for product images, linked to the <code>products</code> table. <code>features</code> Defines distinct product features (e.g., \"Water Resistance\", \"Battery Life\") and their applicable categories (JSONB). <code>product_features</code> A junction table linking products to their respective features (many-to-many relationship). <code>variants</code> Represents specific variations of a product (e.g., based on color, size), including price and stock levels. <code>variant_attributes</code> Stores key-value attributes for each product variant (e.g., <code>attribute_name</code>: \"Color\", <code>attribute_value</code>: \"Blue\"). <code>product_reviews</code> Stores customer reviews, ratings, associated product, user, and AI-extracted sentiment and feature ID. <code>personalized_product_sections</code> Stores AI-generated personalized content (JSONB) for specific user-product combinations, including status and tracing IDs for AI workflows. <code>embeddings_products</code> Vector store holding embeddings for product data (e.g., name, description, category) to enable semantic search for products. <code>embeddings_reviews</code> Vector store holding embeddings for product review text to enable semantic search and analysis of reviews."},{"location":"01-Introduction/04-Data-Structures/#how-these-tables-work-together","title":"How These Tables Work Together","text":"<ol> <li>User data (<code>users</code>) provides context for personalization.</li> <li>Product information (<code>products</code>, <code>product_images</code>, <code>features</code>, <code>product_features</code>, <code>variants</code>, <code>variant_attributes</code>) forms the catalog that AI agents interact with.</li> <li>Customer reviews (<code>product_reviews</code>) are processed by AI to extract sentiment and identify key features discussed.</li> <li>Embeddings (<code>embeddings_products</code>, <code>embeddings_reviews</code>) are generated from product and review text, enabling semantic search and retrieval.</li> <li>AI agents generate personalized content (<code>personalized_product_sections</code>) based on user profiles, product data, reviews, and inventory status.</li> <li>Apache AGE graph data (derived from these tables) models relationships between products, reviews, and features for advanced analytics and explainable AI.</li> </ol>"},{"location":"01-Introduction/04-Data-Structures/#key-fields-used-in-ai-processing","title":"Key Fields Used in AI Processing","text":"<p>AgenticShop integrates with Azure AI services, vector databases, and graph databases to extract, validate, personalize, and process information. Below are key fields that play a crucial role in these AI workflows:</p>"},{"location":"01-Introduction/04-Data-Structures/#relational-vector-ai-fields","title":"Relational, Vector &amp; AI Fields","text":"Field Name Table(s) AI Usage <code>embedding</code> <code>embeddings_products</code>, <code>embeddings_reviews</code> Stores vector embeddings for semantic search, similarity retrieval, and RAG for products and reviews. <code>personalization</code> <code>personalized_product_sections</code> JSONB field storing structured AI-generated content (features, descriptions) tailored to the user and product. <code>specifications</code> <code>products</code> JSONB field for flexible product attributes; can be used by AI to match user needs or extract detailed info. <code>review</code> (text) <code>product_reviews</code> Raw text of customer reviews, processed by NLP models for sentiment analysis and feature extraction. <code>sentiment</code> <code>product_reviews</code> AI-extracted sentiment (positive, negative, neutral) from review text. <code>feature_id</code> <code>product_reviews</code>, <code>product_features</code> Links reviews and products to specific features, enabling targeted analysis and feature-based recommendations. <code>attribute_name</code>, <code>attribute_value</code> <code>variant_attributes</code> Used by AI (e.g., Inventory Agent) to find product variants matching user preferences (e.g., color, size). <code>hobbies</code>, <code>lifestyle_preferences</code>, <code>search_history</code>, <code>age</code>, <code>gender</code>, <code>location</code> <code>users</code> User profile attributes used by AI agents to understand user context and personalize recommendations/content. <code>status</code> <code>personalized_product_sections</code> Tracks the state of AI content generation workflows (pending, running, done, failed). <code>phoenix_trace_id</code> <code>personalized_product_sections</code> Links to observability platforms (like Arize Phoenix) for tracing and debugging AI agent execution."},{"location":"02-Setup/","title":"Deployment","text":"<p>A starter solution has been provided, which is enhanced with AI-rich capabilities throughout this guide. This initial application includes a user-friendly React JS UI, offering an intuitive frontend interface for users to interact with. Additionally, it features a Python-based backend that handles the multi-agent workflow logic and workflow tracing. The guide describes the advanced AI funtionalities which enhance the solution.</p> Ensure you completed the prerequisites before proceeding! <p>Before proceeding, review the prerequisites for following this guide.</p> <p>To build the custom multi-agent workflow application, the following steps are required:</p> <ul> <li>PROVISION the required Azure infrastructure for the resources needed for the application architecture.</li> <li>VALIDATE that the Azure deployment completed successfully.</li> <li>SETUP your development environment and configure it to work with the infrastructure.</li> </ul>"},{"location":"02-Setup/01-Prerequisites/","title":"2.1 Prerequisites","text":"<p>Review the details about what is needed before following this guide, what you are expected to know beforehand and what you can expect to learn after going through it.</p>"},{"location":"02-Setup/01-Prerequisites/#what-you-need","title":"What You Need","text":"<p>To follow this guide, you will need:</p> <ol> <li> <p>Your own computer.</p> <ul> <li>Any computer capable of running Visual Studio Code, Docker Desktop, and a modern web browser will do.</li> <li>You must have the ability to install software on the computer.</li> <li>We recommend installing a recent version of Edge, Chrome, or Safari.</li> </ul> </li> <li> <p>An Azure Subscription.</p> <ul> <li>This is needed to provision the Azure infrastructure for your AI project.</li> <li>If you don't have an Azure account, sign up for a free one now. (It takes just a few minutes.)</li> </ul> </li> <li> <p>User Permissions for Deployment.</p> <ul> <li> <p>In order to deploy AgenticShop successfully in your subscription, following roles must be attached to the user deploying the solution:</p> <ul> <li>Contributor</li> <li>Role Based Access Control Administrator</li> </ul> </li> </ul> </li> <li> <p>Identify a suitable Azure region for your OpenAI models.</p> <p>To successfully deploy and run the solution accelerator with Generative AI capabilities, you must ensure that your Azure subscription has access to the necessary Azure OpenAI models with sufficient quota in at least one supported region.</p> <ul> <li> <p>This solution uses following Azure OpenAI models:</p> <ul> <li><code>gpt-4o</code> with a minimum quota requirement of 50K TPM (<code>GlobalStandard</code>)</li> <li><code>text-embedding-3-small</code> with a minimum quota requirement of 70K TPM (<code>GlobalStandard</code>)</li> </ul> </li> <li> <p>Before proceeding, identify an Azure region where both models are available and you have the required quota. Refer to the following documentation for regional availability:</p> <ul> <li>gpt-4o model availability</li> <li>text-embedding-3-small model availability</li> </ul> </li> <li> <p>You can check your current quota and request increases using the steps outlined here.</p> </li> </ul> <p>Automatic region filtering in <code>azd</code> workflow</p> <p>When you run <code>azd up</code>, the tool automatically filters and displays only those regions that meet the above requirements \u2014 i.e., regions where both models are available and the corresponding quota is sufficient.</p> </li> <li> <p>Select appropriate Azure region for your infrastructure resources.</p> <p>Before selecting an Azure region for infrastructure, you must ensure that the region you have selected supports following Azure services:     - <code>Standard_D2ds_v4</code> Azure Flexible server for PostgreSQL (<code>General Purpose</code>)     - Resource Group     - Azure Key vault     - Azure Container Environment and Azure Container Apps     - Azure Container Registry</p> </li> </ol>"},{"location":"02-Setup/01-Prerequisites/#what-you-should-know","title":"What You Should Know","text":"<p>To get the most of this solution accelerator, you should have:</p>"},{"location":"02-Setup/01-Prerequisites/#recommended-knowledge-and-experience","title":"Recommended knowledge and experience","text":"<ol> <li>Familiarity with Visual Studio Code<ul> <li>The default editor used in this guide is Visual Studio Code. You will configure your VS Code development environment with the required extensions and code libraries.</li> <li>The guide requires Visual Studio Code and other tools to be installed on your computer. You will be running the solution code from your local computer.</li> </ul> </li> <li>Familiarity with the Azure portal<ul> <li>The guide assumes you are familiar with navigating to resources within the Azure portal.</li> <li>You will use the Azure portal to retrieve endpoints, keys, and other values associated with the resources described in this guide.</li> </ul> </li> <li>Familiarity with PostgreSQL<ul> <li>The guide assumes you are familiar with basic SQL syntax.</li> </ul> </li> </ol>"},{"location":"02-Setup/01-Prerequisites/#preferred-knowledge-and-experience","title":"Preferred knowledge and experience","text":"<ol> <li>Familiarity with <code>git</code> operations<ul> <li>You will be cloning the sample repository from Github.</li> </ul> </li> <li>Familiarity with the <code>bash</code> shell.<ul> <li>If needed, you will use <code>bash</code> in the VS Code terminal to run post-provisioning scripts.</li> <li>You will also use it to run Azure CLI and Azure Developer CLI commands during setup.</li> </ul> </li> <li>Familiarity with Python frameworks.<ul> <li>This guide provides an overview of the solution, including relevant Python code components.</li> </ul> </li> </ol>"},{"location":"02-Setup/01-Prerequisites/#what-you-will-take-away","title":"What You Will Take Away","text":"<p>After going through this guide, you will have:</p> <ol> <li> <p>An understanding of the Azure portal and relevant developer tools (e.g., Azure Developer CLI, FastAPI) to streamline end-to-end development workflows for your own AI apps.</p> </li> <li> <p>An understanding of how Azure AI services can be integrated into applications to create powerful AI-enabled applications.</p> </li> </ol>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/","title":"2.2 Development Environment Setup","text":"<p>To simplify setup and ensure consistency, this solution accelerator uses a Dev Container as the exclusive development environment.</p> <p>Dev Containers provide a clean, pre-configured workspace with all necessary tools and dependencies already installed. Whether you're on Windows, macOS, or Linux, using Dev Containers helps you avoid common setup issues and ensures that everyone following the guide is working in the same environment.</p>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/#why-dev-containers","title":"Why Dev Containers?","text":"<p>Using Dev Containers offers several benefits:</p> <ul> <li>\u2705 Consistent Development Environment: Avoid the \u201cit works on my machine\u201d problem by running the same stack across all participants and contributors.</li> <li>\u26a1 Quick Setup: All required dependencies (Python, PostgreSQL tools, CLI utilities, etc.) are pre-installed and version-controlled.</li> <li>\ud83d\udd04 Isolated Workspace: Changes you make inside the container don\u2019t affect your global system setup.</li> <li>\ud83d\udd27 Reproducibility: Easily reproduce the environment in CI/CD pipelines or across teams.</li> <li>\ud83e\uddea Great for Experimentation: Break things without consequences \u2014 just rebuild the container!</li> </ul> <p>Want to understand more about what Dev Containers are and how they work? Check out this short YouTube video by Visual Studio Code (7 mins).</p> <p>\ud83d\udcd8 For deeper documentation, visit the official Dev Container guide.</p>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/#install-prerequisites","title":"Install Prerequisites","text":"<p>To run the Dev Container successfully, you\u2019ll need to install a few tools on your local machine. Once installed, you\u2019ll be able to open the project in VS Code and let it configure everything automatically inside the container.</p> <p>\ud83d\udee0\ufe0f Minimum Setup You only need to install the following system-level tools \u2014 the rest will be handled by the Dev Container itself:</p>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/#install-software","title":"Install Software","text":"<p>The required development environment uses a Visual Studio (VS) Code editor with a Python runtime. To follow this guide, the following software is required:</p> <ul> <li> Git</li> <li> Docker desktop</li> <li> Visual Studio Code</li> </ul>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/#install-git","title":"Install Git","text":"<p>Git enables you to manage your code by tracking changes, maintaining a version history, and facilitating collaboration with others. This helps in organizing and maintaining the integrity of your project's development.</p> <ol> <li> <p>Download Git from https://git-scm.com/downloads.</p> </li> <li> <p>Run the installer using the default options.</p> </li> </ol>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/#install-docker-desktop","title":"Install Docker Desktop","text":"<p>Docker Desktop is an application that allows you to build, share, and run containerized applications on your local machine. It provides a user-friendly interface to manage Docker containers, images, and networks. By streamlining the containerization process, Docker Desktop helps you develop, test, and deploy applications consistently across different environments.</p> <ol> <li> <p>Download and install Docker Desktop for your OS:</p> <ul> <li>Linux</li> <li>Mac</li> <li>Windows</li> </ul> </li> </ol>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/#install-visual-studio-code","title":"Install Visual Studio Code","text":"<p>Visual Studio Code is a versatile, open-source code editor that combines powerful features with an intuitive interface to help you efficiently write, debug, and customize projects. Note that the needed extensions will automatically be installed within the <code>dev container</code>, so no need to install any additional extensions now.</p> <ol> <li> <p>Download and install from https://code.visualstudio.com/download.</p> <ul> <li>Use the default options in the installer.</li> </ul> </li> <li> <p>After installation is completed, launch Visual Studio Code.</p> </li> <li> <p>In the Extensions menu, search for and install the following extensions from Microsoft:</p> <ul> <li>Dev Containers</li> </ul> </li> <li> <p>Close VS Code.</p> </li> </ol>"},{"location":"02-Setup/02-Development-Environment-Setup-Options/#youre-ready-to-launch","title":"\u2705 You're Ready to Launch","text":"<p>Once you\u2019ve installed everything above, you can move to the next step where you\u2019ll clone the repo and then open the cloned repo in VS Code, and it will automatically prompt you to reopen in a Dev Container.</p> <p>From there, VS Code will take care of building the container and installing all required tools inside it.</p> <p>Let\u2019s get started!</p>"},{"location":"02-Setup/03-Clone-Repo/","title":"2.3 Clone the Repository","text":"<p>To get started, clone the postgres-agentic-shop repository directly onto your local machine.</p> <ol> <li>Open a terminal and navigate to the directory where you want to download the repo.</li> <li>Run the following command to clone the repository:     Bash<pre><code>git clone https://github.com/Azure-Samples/postgres-agentic-shop.git\n</code></pre></li> <li>Navigate into the cloned project directory:     Bash<pre><code>cd postgres-agentic-shop\n</code></pre></li> <li>Open the project in Visual Studio Code:     Bash<pre><code>code .\n</code></pre></li> </ol> <p>Tip Leave Visual Studio Code open as you will be using it throughout the remainder of the guide.</p>"},{"location":"02-Setup/04-Setup-Dev-Environment/","title":"2.4 Setup Dev Environment","text":""},{"location":"02-Setup/04-Setup-Dev-Environment/#introduction","title":"Introduction","text":"<p>This section guides you through setting up and configuring the application environment for the solution accelerator. To ensure a consistent and simplified experience across all platforms, we use Dev Containers as the exclusive method for running both the backend and frontend applications.</p> <p>Dev Containers provide a pre-configured, containerized development environment that minimizes manual setup and eliminates version mismatches across systems. You\u2019ll be using Visual Studio Code with Docker to build and open the Dev Container, install required libraries for both Python and Node.js components, and configure essential environment variables.</p> <p>By following these instructions, you will establish a consistent and fully functional development environment tailored for this solution.</p>"},{"location":"02-Setup/04-Setup-Dev-Environment/#confirm-docker-engine-is-running","title":"Confirm Docker Engine is Running","text":"<p>Before proceeding, ensure that the Docker Engine is running on your system. You can check this by running the following command in your terminal or command prompt:</p> Bash<pre><code>docker info\n</code></pre> <p>If Docker is running, this command will display information about your Docker installation. If Docker is not running, you will see an error message.</p>"},{"location":"02-Setup/04-Setup-Dev-Environment/#if-docker-is-not-running","title":"If Docker is Not Running","text":"<p>Follow the instructions below based on your operating system to start the Docker Engine:</p>"},{"location":"02-Setup/04-Setup-Dev-Environment/#linux","title":"Linux","text":"<p>If you installed Docker using a package manager, you can start the Docker service with:</p> Bash<pre><code>sudo systemctl start docker\n</code></pre> <p>To enable Docker to start automatically on boot:</p> Bash<pre><code>sudo systemctl enable docker\n</code></pre>"},{"location":"02-Setup/04-Setup-Dev-Environment/#windows","title":"Windows","text":"<ol> <li>Open the Start menu and search for Docker Desktop.</li> <li>Click on Docker Desktop to launch it.</li> <li>Wait for the Docker icon to appear in your system tray and indicate that Docker is running.</li> </ol>"},{"location":"02-Setup/04-Setup-Dev-Environment/#macos","title":"macOS","text":"<ol> <li>Open Launchpad and search for Docker.</li> <li>Click on Docker to launch Docker Desktop.</li> <li>Wait for the Docker whale icon to appear in your menu bar and indicate that Docker is running.</li> </ol> <p>After starting Docker, re-run <code>docker info</code> to confirm that the Docker Engine</p>"},{"location":"02-Setup/04-Setup-Dev-Environment/#create-env-file-for-apps","title":"Create <code>.env</code> File for Apps","text":"<ol> <li> <p>For each of the following directories, navigate in each directory to create a copy of <code>.env.example</code> file and rename it <code>.env</code> for now. We will populate the required environment variables later in Section 2.7.</p> <p>Create <code>.env</code> files for each directory by following instructions below</p> Bash<pre><code>cp frontend/.env.example frontend/.env\ncp backend/.env.example backend/.env\ncp arize-phoenix/.env.example arize-phoenix/.env\n</code></pre> </li> </ol>"},{"location":"02-Setup/04-Setup-Dev-Environment/#build-and-open-dev-container","title":"Build and Open Dev Container","text":"<p>In this step you will open and build your dev container in VS Code.  After you complete this, you can complete the remaining steps in this page by running all commands inside your dev container command line, not your local operating system command line.</p> <ol> <li>Open VS Code</li> <li>Open Folder of your locally cloned repo</li> <li>Press <code>Ctrl+Shift+P</code> to open the command palette</li> <li>Type: <code>Dev Container</code> and choose \"Rebuild and Reopen in Container\"</li> <li>In case the correct python interpreter is not set by default - open the Command Palette (Ctrl+Shift+P or Cmd+Shift+P on macOS), then search for and select \"Python: Select Interpreter\". From the list, choose the interpreter located in your project's virtual environment (<code>backend/.venv/bin/python</code>).</li> </ol> <p>Dev Container Build Process</p> <p>This will kick off a docker build process where your dev container will be built by docker desktop. Let this process run, it may take a few minutes. You will see VS Code flash and load into a new project environment. Once the process completes, you can open a new terminal in VS Code. You will notice the shell will look a little different as now you are in an Ubuntu Linux Container.</p> <p>From here on out in the documentation, run your commands in the dev container shell.</p>"},{"location":"02-Setup/05-Provision-And-Deploy/","title":"2.5 Provision and Deploy","text":"<p>You will need a valid Azure subscription and access to relevant Azure OpenAI models to complete this lab. Review the prerequisites section if you need more details. After completing this section, you should have:</p> <ul> <li> Authenticated with Azure</li> <li> Provisioned Azure resources for AgenticShop solution</li> </ul>"},{"location":"02-Setup/05-Provision-And-Deploy/#authenticate-with-azure","title":"Authenticate With Azure","text":"<p>Before running the <code>azd up</code> command, you must authenticate your VS Code environment to Azure.</p> <p>To create Azure resources, you need to be authenticated from VS Code. Open a new integrated terminal in VS Code. Then, complete the following steps:</p> <p>Visual Studio Code Integrated terminal</p> <p>The integrated terminal in Visual Studio Code is a built-in console panel that runs your system\u2019s shell such as Bash, PowerShell etc. within the editor. It lets you execute commands without switching windows, and enhances workflow with extensions, persistent sessions, and context-aware shell integration To open an integrated terminal, you can use this keyboard shortcut \"Ctrl + `\" or click View in the Menu Bar \u2192 Click Terminal</p>"},{"location":"02-Setup/05-Provision-And-Deploy/#authenticate-with-az-for-post-provisioning-tasks","title":"Authenticate with <code>az</code> for post-provisioning tasks","text":"<ol> <li> <p>Log into the Azure CLI <code>az</code> using the command below.</p> Bash<pre><code>az login\n</code></pre> </li> <li> <p>Complete the login process in the browser window that opens.</p> <p>If you have more than one Azure subscription, you may need to run <code>az account set -s &lt;subscription-id&gt;</code> to specify the correct subscription to use.</p> </li> </ol>"},{"location":"02-Setup/05-Provision-And-Deploy/#authenticate-with-azd-for-provisioning-managing-resources","title":"Authenticate with <code>azd</code> for provisioning &amp; managing resources","text":"<ol> <li> <p>Log in to Azure Developer CLI. This is only required once per-install.</p> Bash<pre><code>azd auth login\n</code></pre> <p>Alternative if above command fails</p> <p>If the above command fails, use the following flag which will provide a code in the terminal. Copy this code for later use. On pressing enter, a window will open where paste the code you previously copied and you shall be able to login.</p> Bash<pre><code>azd auth login --use-device-code\n</code></pre> <p>Difference between az CLI and azd CLI</p> <p>az CLI is a granular control-plane tool for managing Azure resources such as VMs, networking, storage, etc. and is used when you need fine\u2011grained control over infrastructure configuration.</p> <p>azd CLI is a higher-level, developer-focused workflow tool that scaffolds, provisions, deploys, and monitors entire applications to automates the full app lifecycle, together with IaC, CI/CD, and monitoring so you don't handcraft each resource individually.</p> </li> </ol>"},{"location":"02-Setup/05-Provision-And-Deploy/#postgresql-admin-credentials-auto-generated","title":"PostgreSQL Admin Credentials (auto-generated)","text":"<p>NOTE: This solution uses PostgreSQL username/password authentication. During deployment (<code>azd up</code>), the admin username and password are auto-generated and written to your project\u2019s <code>.env</code> file.</p> <p>Do not commit secrets</p> <p>Keep your <code>.env</code> file out of version control.</p> <ol> <li> <p>Deploy the infrastructure with <code>azd up</code>. When it completes, open the generated <code>.env</code> file in your project to view the admin credentials.</p> </li> <li> <p>Use the values from <code>.env</code> whenever you need to connect to the database locally (e.g., via a client or CLI). Treat these as secrets.</p> </li> </ol> <p>Example <code>.env</code> entries (values will differ):</p> Text Only<pre><code>DB_USER=rtadmindm2wsm\nDB_PASSWORD=Aa1_161a08227c7145dd9e5441741cc776a0\n</code></pre>"},{"location":"02-Setup/05-Provision-And-Deploy/#provision-azure-resources","title":"Provision Azure Resources","text":"<p>You are now ready to provision your Azure resources.</p> <ol> <li> <p>Use <code>azd up</code> to provision your Azure infrastructure.</p> Bash<pre><code>azd up\n</code></pre> <p>You will be prompted for several inputs for the <code>azd up</code> command:</p> <ul> <li>Enter a new environment name: Enter a value, such as <code>dev</code>.</li> <li>The environment for the <code>azd up</code> command ensures configuration files, environment variables, and resources are provisioned and deployed correctly.</li> <li>Select an Azure Subscription to use: Select the Azure subscription you are using for this workshop using the up and down arrow keys.</li> <li>Select an Azure locations to use: <ul> <li>The list of locations shown is where both Azure OpenAI models used in the application are available.</li> </ul> </li> <li>Select an existing Resource Group or create a new one<ul> <li>(Only if creating a new Resource Group) Enter a value for <code>resourceGroupName</code>: for example, <code>rg-dev</code> or a similar name.</li> </ul> </li> </ul> <p>Pre-deployment Validation Checks</p> <p>Before the <code>azd</code> workflow proceeds, checks are performed in the selected region and recommendations are generated on failure for following cases to ensure that the deployment is successful:</p> <ul> <li>Azure Flexible Server for PostgreSQL SKU</li> <li>Azure Container Apps quota</li> <li>azd env name    </li> </ul> </li> <li> <p>Wait for the process to complete. The above commands will provision the resources, build the application containers and deploy it on Azure Container Apps. It can take close to 30 minutes.</p> <p>Provisioned Resources</p> <p>When you execute the <code>azd up</code> command, following resources will be provisioned in your subscription. You can view these resources in the resource group you have provisioned.</p> Service Name Azure Flexible server for PostgreSQL Azure OpenAI Service </li> <li> <p>On successful completion you will see a <code>SUCCESS: Your up workflow to provision and deploy to Azure completed in xx minutes xx seconds.</code> message on the console. When deployment completes, azd will display the application URLs for the deployed services. Be sure to note these URLs\u2014especially the one for the frontend. If needed, you can always retrieve them later from the Azure Container Apps portal.</p> </li> </ol>"},{"location":"02-Setup/05-Provision-And-Deploy/#troubleshooting-errors","title":"Troubleshooting Errors","text":""},{"location":"02-Setup/05-Provision-And-Deploy/#errors-during-azd-workflow","title":"Errors During azd Workflow","text":"<ol> <li> <p>Error: \"Deployment failed: The resource entity provisioning state is not terminal\"</p> <p>If your deployment faces an error like such as \"The resource entity provisioning state is not terminal\", try running your deployment again using <code>azd up</code>.</p> Bash<pre><code>ERROR: error executing step command 'provision': deployment failed: error deploying infrastructure: deploying to resource group: Deployment Error Details: RequestConflict: Cannot modify resource with id '/subscriptions/{sub-id}/resourceGroups/{rg-name}/providers/Microsoft.CognitiveServices/accounts/{Resourcename}' because the resource entity provisioning state is not terminal. Please wait for the provisioning state to become terminal and then retry the request.\n</code></pre> </li> <li> <p>Error: \"Validation Error\"</p> <p>If your deployment failed with an error such as validation error, you must name the <code>azd</code> env with rules and restrictions for naming conventions. To fix this error, you can create a new <code>azd</code> env with <code>azd env new</code> with supported naming convention and proceed with the deployment steps mentioned in previous section.</p> Bash<pre><code>InvalidTemplateDeployment: The template deployment 'dev' is not valid according to the validation procedure.\n</code></pre> </li> <li> <p>Error: \"Network Issues\"</p> <p>At any point during provisioning of resources, the deployment can fail due to transient errors or network issues. For such occurrences, you can take either of following actions:</p> <ul> <li> <p>Restart the deployment with <code>azd up</code> command.</p> </li> <li> <p>If the above fails, you can delete the existing deployment with <code>azd down --purge</code>, create a new <code>azd</code> env with <code>azd env new</code> and follow the deployment steps from previous section.</p> </li> </ul> </li> </ol>"},{"location":"02-Setup/05-Provision-And-Deploy/#destroy-old-deployment-and-create-new","title":"Destroy Old Deployment and Create New","text":"<ol> <li> <p>If your deployment failed and you want to create a new deployment, you must first purge the previous deployment using <code>azd down --purge</code> command before creating a new deployment with a new <code>azd</code> env. To create new <code>azd</code> env, you must execute <code>azd env new</code> command and input the name for the new <code>azd</code> env.</p> </li> <li> <p>You might run into following error when executing <code>azd down --purge</code> command when you have not approved quota before or have not approved yet:</p> <p>No Deployment Found!</p> <p>ERROR: deleting infrastructure: error deleting Azure resources: finding completed deployments: 'dev': no deployments found.</p> <p>To resolve this error, you must either execute the following <code>az</code> CLI command or delete that specific resource group from Azure portal. Executing the command will ask you for a confirmation to delete resource group. Input <code>y</code> to confirm deletion. Redeploy the env using <code>azd up</code> command.</p> Bash<pre><code>az group delete --name &lt;resource-group-name&gt;\nAre you sure you want to perform this operation? (y/n): y\n\nazd up\n</code></pre> </li> <li> <p>If you intend to create a new deployment after destroying the resources, you can perform any one of the following operations:</p> <ul> <li> <p>You can delete the folder of that env in the <code>.azure</code> folder in root directory that you created before and run the <code>azd up</code> command again to create a new deployment.</p> </li> <li> <p>You can execute the following command to create a new deployment and run the <code>azd up</code> command for new deployment.</p> </li> </ul> Bash<pre><code>azd env new\n\nazd up\n</code></pre> </li> </ol>"},{"location":"02-Setup/06-Validate-Deployment/","title":"2.6 Validate Deployment","text":"<p>SETUP IS COMPLETE!</p> <p>You just completed the PROVISION and SETUP steps of guide. </p> <ul> <li> You installed the required tools and software</li> <li> You cloned the sample repo and created a local clone</li> <li> You provisioned infrastructure resources on Azure</li> <li> You configured your local development environment</li> </ul> <p>Here's a reminder of the Azure Application Architecture you can reference as you check your provisioned Resource Group to ensure these resources were created.</p> <p></p> <p>In this section, you will validate your setup before moving on to the next phase of solution development.</p>"},{"location":"02-Setup/06-Validate-Deployment/#inspect-deployed-azure-resources","title":"Inspect deployed Azure resources","text":"<p>The Azure Portal allows you to view the resources provisioned on Azure and verify that they are setup correctly</p> <ol> <li> <p>Open the Azure portal Resource Group page in a new browser tab. You may be prompted to login.</p> </li> <li> <p>You may be presented with a \"Welcome to Microsoft Azure\" screen. Select Cancel (to dismiss it) or click Get Started (to take an introductory tour of the Azure Portal).</p> </li> <li> <p>You should be taken directly to the Resource Groups page for your subscription. In the list of resource groups, locate the one named <code>rg-dev</code> (or, if you assigned a different name, find that one). This resource group was created for you as part of the <code>azd up</code> resource deployment. It contains all of the Azure resources required to build and deploy your AI-powered solution.</p> <p>You can use the search filter to reduce the number of resource groups displayed.</p> </li> <li> <p>Select your resource group.</p> <p>Review the list of deployed resources.</p> <p>In addition to creating a resource group, the <code>azd up</code> command deployed multiple resources into that resource group, as shown in the table below.</p> Resource type Name Container Registry <code>dev&lt;unique_string&gt;</code> Key Vault* <code>dev-&lt;unique_string&gt;</code> Container Apps Environment <code>dev-&lt;unique_string&gt;</code> Azure Database for PostgreSQL - Flexible Server <code>dev&lt;unique_string&gt;</code> Azure OpenAI <code>dev-&lt;unique_string&gt;</code> Container App <code>rt-frontend</code> Container App <code>rt-backend</code> Container App <code>arize</code> <p>The <code>&lt;unique_string&gt;</code> token in the above resource names represents the unique string that is generated by the Bicep scripts when naming your resources. This ensures resources are uniquely named and avoid resource naming collisions.</p> </li> </ol>"},{"location":"02-Setup/06-Validate-Deployment/#ensure-the-azure-flexible-server-for-postgresql-is-deployed","title":"Ensure the Azure Flexible Server for PostgreSQL is deployed","text":"<p>The <code>azd up</code> command included steps to deploy the Azure Flexible Server for PostgreSQL. This server will store all the data and information related to the solution as well as use multiple postgres extensions used by the backend app to provide the multi-agent workflow functionalities.</p> <p>Azure Flexible Server deployment</p> <p>Azure Database for PostgreSQL Flexible Server is a fully managed database service designed to provide more granular control and flexibility over database management functions and configuration settings. The service generally provides more flexibility and server configuration customizations based on user requirements.</p>"},{"location":"02-Setup/06-Validate-Deployment/#view-azure-openai-model-deployments-in-azure-ai-foundry","title":"View Azure OpenAI model deployments in Azure AI Foundry","text":"<p>The Azure AI Foundry portal lets you view and manage the Azure AI resources for your app.</p> <p>You will use the Azure AI Foundry portal to verify the <code>gpt-4o</code> and <code>text-embedding-3-small</code> models were deployed into your Azure OpenAI service.</p> <ol> <li> <p>In the Azure portal, return to the resource group containing your resources and select the Azure OpenAI resource.</p> </li> <li> <p>On the Azure OpenAI resource's Overview page, select Go to Azure AI Foundry portal.</p> </li> <li> <p>In Azure AI Foundry, select the Deployments menu item under Shared resources in the left-hand navigation menu.</p> </li> <li> <p>Verify you see a <code>gpt-4o</code> deployment for the <code>gpt-4o</code> model and a <code>text-embedding-3-small</code> deployment for the <code>text-embedding-3-small</code> model.</p> </li> <li> <p>Ensure that the models that you have deployed have the required quota and deployment type.</p> <p></p> </li> </ol> <p>Leave the Azure Portal open. You will revisit it later.</p>"},{"location":"02-Setup/06-Validate-Deployment/#test-the-deployed-app","title":"Test the Deployed App","text":"<ol> <li> <p>In the Azure portal, return to the resource group containing your resources and select the Frontend Container App resource.</p> </li> <li> <p>In the Essentials section of the Portal Container App's Overview page, select the Application URL to open the deployed AgenticShop app in a new browser tab.</p> <p></p> </li> <li> <p>In the AgenticShop landing page, select any User and you can see the home page where all the products are listed!</p> <p></p> </li> <li> <p>You can select any product and the UI will show you the details and personalized recommendations of the products powered by AI models.</p> </li> </ol>"},{"location":"02-Setup/07-Setting-Up-Env-files/","title":"2.7 [OPTIONAL] Setting Up Environment (.env) Files","text":"<p>Info</p> <p>Up to this point, the guide has walked through deploying the complete solution on Azure. In the next sections, you will learn how to set up the application environment locally, while continuing to use the database and Azure OpenAI services hosted in the cloud.</p> <p>These steps are optional, but they are useful if you want to run and test the application from your own development machine.</p> <p>Environment variable files (<code>.env</code>) are essential for securely managing configuration values such as API keys, service URLs, and secrets for each application component. This section guides you through setting up <code>.env</code> files for the frontend, backend, and arize-phoenix services.</p>"},{"location":"02-Setup/07-Setting-Up-Env-files/#1-overview","title":"1. Overview","text":"<p>After deploying your services on Azure (see section 2.6), a <code>.env</code> file is generated in the root directory of your project. This file contains all the necessary environment variable values (URLs, keys, etc.) for the deployed services. You do not need to manually retrieve these values from the Azure portal.</p> <p>To complete your setup:</p> <ul> <li>Copy the relevant variables from the root <code>.env</code> file into the <code>.env</code> files for each service as described below.</li> </ul>"},{"location":"02-Setup/07-Setting-Up-Env-files/#2-create-env-file-for-apps","title":"2. Create <code>.env</code> File for Apps","text":"<ol> <li> <p>For each of the following directories, navigate in each directory to create a copy of <code>.env.example</code> file and rename it <code>.env</code> for now.</p> <p>Create <code>.env</code> files for each directory by following instructions below</p> Bash<pre><code>cp frontend/.env.example frontend/.env\ncp backend/.env.example backend/.env\ncp arize-phoenix/.env.example arize-phoenix/.env\n</code></pre> </li> </ol>"},{"location":"02-Setup/07-Setting-Up-Env-files/#3-backend-setting-up-env-file","title":"3. Backend: Setting up <code>.env</code> file","text":"<ol> <li>In the <code>backend</code> directory, create a file named <code>.env</code> if it does not already exist.</li> <li>Copy the backend-related variables from the root <code>.env</code> file. Typical variables include:<ul> <li><code>DB_HOST</code></li> <li><code>DB_PASSWORD</code></li> <li><code>DB_NAME</code></li> <li><code>DB_USER</code></li> <li><code>AZURE_OPENAI_API_KEY</code></li> <li><code>AZURE_OPENAI_ENDPOINT</code></li> <li><code>AZURE_API_VERSION_LLM</code></li> <li><code>AZURE_API_VERSION_EMBEDDING_MODEL</code></li> <li>Any other variables required by the backend (refer to sample <code>.env.example</code>).</li> </ul> </li> <li>Paste these variable values into <code>backend/.env</code>.</li> </ol>"},{"location":"02-Setup/07-Setting-Up-Env-files/#4-frontend-setting-up-env-file","title":"4. Frontend: Setting up <code>.env</code> file","text":"<ol> <li>In the <code>frontend</code> directory, create a copy of file named <code>.env.example</code> and rename it to <code>.env</code> if it does not already exist.</li> <li>Set the below variable to the following.<ul> <li><code>VITE_BE_APP_ENDPOINT=http://127.0.0.1:8000/</code></li> </ul> </li> </ol>"},{"location":"02-Setup/07-Setting-Up-Env-files/#5-arize-phoenix-setting-up-env-file","title":"5. Arize-Phoenix: Setting up <code>.env</code> file","text":"<p>By default, we recommend not setting the environment variable below for Arize Phoenix. In this case, traces will be stored locally inside the container using a Docker volume, and will persist as long as the Docker volume exists. However, if the volume is removed, traces will be lost.</p> <p>If you want to persist traces to an external database, follow the steps below to configure the connection.</p> <ol> <li>In the <code>arize-phoenix</code> directory, create a file named <code>.env</code> if it does not already exist.</li> <li>Copy the Arize-related variables from the root <code>.env</code> file. Typical variables include:<ul> <li><code>PHOENIX_SQL_DATABASE_URL</code> (set this only if you want to persist traces externally)</li> </ul> </li> <li>Paste these variables into <code>arize-phoenix/.env</code>.</li> </ol> <p>If you do not set <code>PHOENIX_SQL_DATABASE_URL</code>, Arize Phoenix will use its default local storage for traces.</p>"},{"location":"02-Setup/07-Setting-Up-Env-files/#6-summary","title":"6. Summary","text":"<ul> <li>In case of new deployment, always update your service-specific <code>.env</code> files with the latest values from the root <code>.env</code> file.</li> <li>This process ensures each app has the correct configuration and can connect to the necessary Azure resources securely.</li> </ul> <p>Never commit <code>.env</code> files with secrets to version control. Use <code>.gitignore</code> to keep them private.</p>"},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/","title":"2.8 [OPTIONAL] Configure PostgreSQL for VS Code","text":"<p>This guide walks you through setting up the PostgreSQL extension for Visual Studio Code, which provides a powerful, integrated database management experience directly within your development environment. Instead of using external applications, you'll be able to connect to, query, and manage your Azure Database for PostgreSQL Flexible Server instance seamlessly from VS Code. We'll be utilizing this to run queries and for any other database interactions.</p>"},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/#installation","title":"Installation","text":"<p>In our setup, this extension already gets installed when the devcontainer is being build. Nonetheless, to install it manually, search for <code>Postgres</code> in the extensions sidebar and install the one developed by Microsoft.</p> <p> </p>"},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/#connecting-with-our-database","title":"Connecting with our Database","text":"<p>We'll connect the extension to the database server of our application.</p>"},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/#click-on-the-postgresql-extension","title":"Click on the PostgreSQl extension","text":""},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/#select-add-connection-option","title":"Select 'add connection' option","text":""},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/#add-details-we-use-agentic-shop-db-as-are-server-name-for-the-purpose-of-this-guide","title":"Add details. We use \"Agentic Shop DB\" as are Server Name for the purpose of this guide.","text":"<p>Look for the connection details from <code>src/.env</code> and add them here.</p> <p></p> <p>Use the following mapping to find the correct values from your <code>.env</code> file:</p> Parameter .env variable SERVER_NAME DB_HOST USER_NAME DB_USER PASSWORD DB_PASSWORD DATABASE_NAME DB_NAME"},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/#connected","title":"Connected","text":"<p>Connected to our database server.</p> <p></p>"},{"location":"02-Setup/08-Configure-PostgreSQL-for-VSCode/#the-extension-is-now-setup-and-connected-to-our-database-server-well-now-use-this-throughout-the-guide-to-interact-with-the-database","title":"The extension is now setup and connected to our database server. We'll now use this throughout the guide to interact with the database.","text":""},{"location":"02-Setup/09-Run-Application/","title":"2.9 [OPTIONAL] Run Application","text":""},{"location":"02-Setup/09-Run-Application/#database-setup","title":"Database Setup","text":"<p>Before starting the backend or frontend application, the database must have the required tables and schema. This is handled automatically: when you deploy the app using <code>azd up</code>, all necessary <code>alembic</code> migrations are executed as part of the backend deployment process. You do not need to run any migration commands manually\u2014your database will always be up to date after deployment.</p> <p>In future, if there is a need to make updates to the database, a new migration file can be added and the migrations can be re-run to update the database using the command <code>alembic upgrade head</code>. This can be done in two ways:</p> <ul> <li> <p>Local Machine : From within the devcontainer of your local machine, navigate to the backend directory and run <code>alembic upgrade head</code> (Make sure your virtual environment is activated. Refer to Section 2.4).</p> </li> <li> <p>Redeploy Backend Service : Run <code>azd deploy backend</code> to deploy the backend service again. This process automatically re-runs the migrations from the backend container app server, updating the database. Because the backend container app, the database and other required services are in the same resource group, migrations typically execute faster this way than running them from your local machine.</p> </li> </ul> <p>For detailed guidance on Alembic migrations, see Section 3.2: Alembic Migrations of this guide.</p>"},{"location":"02-Setup/09-Run-Application/#run-apps-using-vs-code-debugger","title":"Run Apps Using VS Code Debugger","text":"<p>You can use the VS Code debugger to start the backend, frontend, or both at once:</p> <ol> <li>Open the Run &amp; Debug panel in VS Code (<code>Ctrl+Shift+D</code>).</li> <li>Select one of the following configurations from the dropdown:<ul> <li>Launch Backend: FastAPI \u2013 starts the backend (also starts Arize container automatically via preLaunchTask).</li> <li>Launch Frontend (UI) \u2013 starts the frontend app.</li> <li>Launch Frontend and Backend \u2013 starts both apps simultaneously.</li> </ul> </li> <li>Click the green play button to start the applications.</li> </ol> <p></p> <p>The compound configuration Launch Frontend and Backend will run both apps together, each in its own debugger instance.</p>"},{"location":"02-Setup/09-Run-Application/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues while running the application, consider the following common solutions:</p> <ul> <li> <p>Error Starting Backend App</p> <p>While starting the backend app from debugger you might face this error <code>No module named uvicorn</code>. If you have completed the step of installing backend project dependencies using <code>poetry install</code>, then this error means that vscode is not pointing to correct python interpreter.</p> <p>To fix this error, open the command panel in vscode using <code>ctrl + shift + p</code> type <code>Python: Select Interpreter</code> and press enter. </p> <p>Choose the interpreter that is in our backend project virtual environment. </p> </li> <li> <p>Database Migration Errors:   Ensure your database service is running and accessible. Double-check your environment variables for correct database connection details. Rerun the migration command if necessary.</p> </li> <li> <p>Port Conflicts:   Make sure ports <code>8000</code> (backend), <code>5173</code> (frontend), and <code>6006</code> (Arize Phoenix) are not in use by other applications. Stop any conflicting services or change the port numbers in your configuration.</p> </li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/","title":"Integrate Generative AI into Azure Database for PostgreSQL \u2013 Flexible Server","text":"<p>The AgenticShop prototype showcases how Generative AI (GenAI) can be deeply integrated into your database infrastructure to power intelligent e-commerce experiences. Built on Azure Database for PostgreSQL \u2013 Flexible Server, this solution leverages a combination of vector search, graph modeling, and in-database AI to deliver advanced personalization and product discovery.</p> <p>GenAI uses natural language processing (NLP) techniques like prompting and retrieval-augmented generation (RAG) to understand user intent, extract actionable insights, and generate personalized responses. This enables use cases like:</p> <ul> <li>Extracting structured features and sentiments from unstructured product reviews</li> <li>Modeling user\u2013product\u2013review relationships as a graph</li> <li>Powering multi-modal product discovery: \u201cHeadphones with positive reviews about noise cancellation\u201d</li> <li>Dynamically updating personalization profiles based on user conversations</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/#postgresql-extensions-used-in-this-poc","title":"PostgreSQL Extensions Used in This POC","text":"<p>This solution integrates several key PostgreSQL extensions to enable AI-native capabilities:</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/#azure_ai","title":"<code>azure_ai</code>","text":"<p>The Azure AI extension allows direct interaction with Azure\u2019s AI services from within SQL. In AgenticShop, it is used to:</p> <ul> <li>Extract product features and sentiment scores from free-text reviews during data ingestion</li> <li>Enable in-database feature tagging for downstream personalization and filtering</li> <li>Integrate seamlessly with LLMs like Azure OpenAI</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/#vector-and-pg_diskann","title":"<code>vector</code> and <code>pg_diskann</code>","text":"<p>The vector extension enables storage and querying of vector embeddings alongside your data. The pg_diskann extension provides high-speed, scalable approximate nearest neighbor (ANN) search using the DiskANN algorithm.</p> <p>These are used to:</p> <ul> <li>Store semantic embeddings for product descriptions and reviews</li> <li>Perform fast vector similarity queries via LlamaIndex</li> <li>Power smart search experiences in real-time</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/#apache_age","title":"<code>apache_age</code>","text":"<p>The Apache AGE extension transforms your PostgreSQL database into a graph database, enabling:</p> <ul> <li>Representation of complex relationships like:   User \u2192 wrote \u2192 Review \u2192 talks_about \u2192 Feature \u2192 belongs_to \u2192 Product</li> <li>Querying with Cypher to answer:</li> <li>\u201cHeadphones with positive reviews about noise cancellation\u201d</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/#what-youll-do-in-this-section","title":"What You'll Do in This Section","text":"<p>In this module, we will walk through how our PostgreSQL database is setup via Bicep and Alembic migrations to support these AI-driven capabilities:</p> <ul> <li> Install Extensions</li> <li> <p>Install <code>azure_ai</code>, <code>pg_diskann</code>, <code>vector</code>, and <code>apache_age</code></p> </li> <li> <p> Configure Azure AI Integration</p> </li> <li> <p>Set up <code>azure_ai</code> with connection credentials for Azure OpenAI</p> </li> <li> <p> Embed Intelligence into Data</p> </li> <li>Generate and store embeddings for product content and reviews</li> <li> <p>Use <code>azure_ai</code> to extract sentiment and key features from raw reviews</p> </li> <li> <p> Enable Scalable Search</p> </li> <li> <p>Improve vector query performance with DiskANN</p> </li> <li> <p> Enable Graph-Based Reasoning with Apache AGE</p> </li> <li>Model relationships between users, reviews, features, and products as a graph</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/#note-on-steps","title":"Note on Steps","text":"<ul> <li>This section is included to show what is happening behind the scenes.</li> <li>The full setup is automated using Infrastructure-as-Code (IaC) via Bicep scripts, which provision the database and configure the required extensions.</li> <li>Data ingestion, vector generation, and in-database AI processing (e.g., feature and sentiment extraction) are executed during application bootstrapping using Alembic, a lightweight database migration tool for Python. Alembic ensures database schema consistency across environments.</li> <li>Vector embeddings for product content and reviews are generated using the LlamaIndex framework and stored in the database during these migrations.</li> </ul> <p>This walk-through will help you:</p> <ul> <li>Understand how the PostgreSQL extensions are configured</li> <li>See how embeddings and AI operations are applied to data during migrations</li> <li>Gain visibility into what\u2019s automated behind the scenes via Bicep and Alembic</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/01-Postgres-Extensions/","title":"3.1 Install Extensions","text":"<p>Azure Database for PostgreSQL Flexible Server allows you to extend the functionality of your database using extensions. Extensions bundle multiple related SQL objects into a single package that can be loaded or removed from your database with a single command. After being loaded into the database, extensions function like built-in features.</p> <p>\u2705 These steps have already been executed automatically via our Bicep infrastructure deployment as part of the provisioning process. The content below is included for reference and understanding of what was configured behind the scenes.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/01-Postgres-Extensions/#allowlist-the-extensions","title":"Allowlist the Extensions","text":"<p>To enable extensions in Azure Database for PostgreSQL Flexible Server, they must first be added to the server's allowlist.</p> <p>You can also review how this is done manually in the official documentation. The documentation includes steps for allowlisting the extensions, follow the instructions provided in the link.</p> Azure CLI Bash<pre><code>az postgres flexible-server parameter set \\\n  --resource-group [YOUR_RESOURCE_GROUP] \\\n  --server-name [YOUR_POSTGRESQL_SERVER] \\\n  --subscription [YOUR_SUBSCRIPTION_ID] \\\n  --name azure.extensions \\\n  --value azure_ai,pg_diskann,vector,age\n</code></pre> <p>This step is handled automatically by Bicep during deployment.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/01-Postgres-Extensions/#install-extensions","title":"Install Extensions","text":"<p>Once allowlisted, extensions are installed in your database. This is also fully automated by the deployment process using Alembic migrations and Bicep scripts.</p> <p>You may optionally inspect or manually install them using SQL</p> Azure AI extensionpgvector extensionDiskANN extensionApache AGE extension SQL<pre><code>CREATE EXTENSION IF NOT EXISTS azure_ai;\n</code></pre> <p>Enables AI-powered capabilities by connecting your database with Azure OpenAI and Cognitive Services for operations like sentiment analysis, embedding generation, and text extraction.</p> SQL<pre><code>CREATE EXTENSION IF NOT EXISTS vector;\n</code></pre> <p>Adds support for storing and querying vector embeddings\u2014used to enable semantic search and similarity ranking.</p> SQL<pre><code>CREATE EXTENSION IF NOT EXISTS pg_diskann;\n</code></pre> <p>Supports fast and scalable approximate nearest neighbor (ANN) search, optimized for large vector datasets.</p> SQL<pre><code>CREATE EXTENSION IF NOT EXISTS age;\n</code></pre> <p>Enables graph database capabilities within PostgreSQL using Apache AGE. Allows you to model relationships and run Cypher queries for graph traversal and reasoning.</p> <p>DiskANN depends on pgvector</p> <p>Make sure the <code>vector</code> extension is created before or use <code>CASCADE</code> to automatically handle dependencies.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/01-Postgres-Extensions/#verify-installed-extensions","title":"Verify Installed Extensions","text":"<p>To verify which extensions are currently installed:</p> <ol> <li>Click on Postgres extension.</li> <li>Go to Agentic Shop DB &gt; Databases &gt; agentic_shop &gt; Schemas &gt; public &gt; Extensions. You can see the list of installed extensions.</li> <li> <p>Alternatively, go to Agentic Shop DB &gt; Databases, right click on agentic_shop and select New Query. </p> <p></p> </li> </ol> <p>Paste the following and run it. You will see the list of extensions installed:</p> SQL<pre><code>SELECT * FROM pg_available_extensions WHERE installed_version IS NOT NULL;\n</code></pre> <p>It will show the following output, listing all the extensions currently installed in your PostgreSQL instance.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/01-Postgres-Extensions/#_1","title":"3.1 Install Extensions","text":"<p>If you're interested in understanding how these are configured programmatically, you can explore the Bicep deployment scripts. Refer to the post provision azd hook for understanding.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/02-Alembic-Migrations/","title":"3.2 Alembic Migrations","text":"<p>In this section, you'll learn about how Alembic is used to manage the database schema in the AgenticShop backend.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/02-Alembic-Migrations/#what-is-alembic","title":"What is Alembic?","text":"<p>Alembic is a lightweight database migration tool for Python. It is commonly used alongside SQLAlchemy to manage schema changes over time while preserving data. Alembic enables you to apply version-controlled changes to your database, ensuring consistent environments across development, staging, and production.</p> <p>In the AgenticShop solution, Alembic plays a central role in:</p> <ul> <li>Creating and modifying relational schema (tables, indexes, constraints)</li> <li>Populating initial data from CSVs</li> <li>Generating and storing vector embeddings</li> <li>Applying in-database AI operations using the <code>azure_ai</code> extension</li> <li>Building a graph layer using Apache AGE for advanced search and reasoning</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/02-Alembic-Migrations/#why-use-alembic-in-this-project","title":"Why Use Alembic in This Project?","text":"<p>Instead of requiring manual SQL scripts, Alembic automates:</p> <ul> <li>The full setup of the PostgreSQL schema</li> <li>Seeding and cleaning data</li> <li>Integration with AI services and vector store configuration</li> <li>Controlled rollouts of graph-based data structures</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/02-Alembic-Migrations/#where-to-find-the-migration-code","title":"Where to Find the Migration Code","text":"<p>The migration scripts are located in the <code>backend/alembic/versions</code> directory of the repository. Each migration file corresponds to a specific step in the data setup.</p> <p>Alembic tracks which migrations have already been applied. If you run the migration command again and there are no new migrations, nothing will change. Only newly created migration scripts will be executed. We have already executed the Alembic migrations and set up the database.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/03-Schema-And-Seeding-Data/","title":"3.3 Creating Schema and Seeding Data","text":"<p>In this section, we set the foundation for our agentic application by:</p> <ul> <li>Creating all the relational database tables used by the system</li> <li>Loading seed data from CSV files into PostgreSQL</li> <li>Populating user preferences into memory using <code>mem0</code></li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/03-Schema-And-Seeding-Data/#database-tables-created","title":"Database Tables Created","text":"<p>Tables include:</p> <ul> <li><code>products</code></li> <li><code>users</code></li> <li><code>product_reviews</code></li> <li><code>features</code></li> <li><code>variants</code></li> <li><code>personalized_product_sections</code> (tracks agent output)</li> </ul> <p>These tables are structured with appropriate foreign keys, indexes, and enum types required by the application.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/03-Schema-And-Seeding-Data/#seeding-data-from-csv","title":"Seeding Data from CSV","text":"<p>CSV files stored in the <code>backend/data/</code> directory are used to populate:</p> <ul> <li>Products and their variants</li> <li>Users</li> <li>Feature definitions</li> <li>Product reviews</li> </ul> <p>The seeding process automatically replaces empty values with <code>NULL</code> and ensures data consistency.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/03-Schema-And-Seeding-Data/#initializing-memory-with-user-preferences","title":"Initializing Memory with User Preferences","text":"<p>User preferences are loaded from CSV into the <code>mem0</code> memory engine:</p> Python<pre><code>output = memory.add(\n    messages=preference,\n    user_id=str(user_id),\n)\n</code></pre> <p>This gives each user a base profile which downstream agents will reference to generate personalized results.</p> <p>We'll explore memory in more detail in the next section.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/","title":"3.4 Generating Memories","text":"<p>In any agentic application, memory is a foundational component. It allows agents to retain information about a user\u2014such as preferences, behaviors, or past interactions\u2014and use that knowledge to deliver personalized experiences.</p> <p>In AgenticShop, we use <code>mem0</code> as the memory engine for storing and retrieving user-specific insights.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#what-does-memory-do","title":"What Does Memory Do?","text":"<p>Memory enables agents to:</p> <ul> <li>Track individual user preferences (e.g., preferred brands, features, or categories)</li> <li>Evolve recommendations based on historical interactions</li> <li>Persist state across workflows and sessions</li> </ul> <p>Example: If a user mentions in the command prompt \"always show critical reviews about durability\", that preference is stored and reused by downstream agents. This is further covered in Trigger Personalization and Memory Update.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#how-is-memory-initialized","title":"How Is Memory Initialized?","text":"<p>During the data seeding phase of the guide, we load preconfigured user preferences from a CSV file. These are injected into <code>mem0</code> using the following logic:</p> Python<pre><code>output = memory.add(\n    messages=preference,\n    user_id=str(user_id),\n)\n</code></pre> <p>This script is executed as part of the Alembic data seeding migration. It ensures each user starts with a base set of memory entries.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#memory-is-dynamic","title":"Memory Is Dynamic","text":"<p>While the initial preferences come from seed data, memories are continuously updated during runtime. For example:</p> <ul> <li>If a user says, \u201cI prefer to read critical reviews about durability,\u201d during his session, this information is recorded.</li> <li>Agents refer to the stored memories to personalize the output.</li> <li>Updates are made transparently as part of agent execution logic.</li> </ul> <p>We\u2019ll explore runtime memory updates in later sections during interactive agent flows.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#try-it-yourself-create-memories-manually","title":"Try It Yourself: Create Memories Manually","text":"<p>You can try storing user memories in an interactive shell within the devcontainer. Here's how:</p> <p>Info</p> <p>For this to work, make sure you have completed the optional steps in Section 2.</p> <p>Try creating new memories by following this section</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#step-1-open-the-python-repl-inside-your-devcontainer","title":"Step 1: Open the Python REPL inside your devcontainer","text":"Bash<pre><code>cd backend\npython -m asyncio\n</code></pre>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#step-2-create-a-memory-instance-and-add-preferences","title":"Step 2: Create a memory instance and add preferences","text":"Python<pre><code>from src.config.memory import get_mem0_memory\n\nmemory = get_mem0_memory()\n\n# Simulate adding preferences for user_id=1\nawait memory.add(messages=\"Prefers long battery life\", user_id=\"1\")\nawait memory.add(messages=\"Interested in noise-cancelling headphones\", user_id=\"1\")\n</code></pre>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#step-3-retrieve-whats-stored-optional","title":"Step 3: Retrieve what\u2019s stored (optional)","text":"Python<pre><code>results = await memory.search(query=\"User's specific preferences, likes, dislikes, past interactions, and shopping behavior patterns?\", user_id=\"1\")\nprint(results)\n</code></pre> <p>These memory entries will now influence how the personalization agent tailors product recommendations in later steps.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#step-4-viewing-stored-memories-in-postgresql","title":"\ufe0fStep 4: Viewing Stored Memories in PostgreSQL","text":"<p>All memories stored by <code>mem0</code> are persisted in a dedicated PostgreSQL table called <code>mem0_chatstore</code>. This table is managed internally by the mem0 framework\u2014you don't need to create or modify it manually.</p> <p>To inspect the memory data stored for different users, you can run the following SQL query. You can utilize the Postgres extension to run it.</p> SQL<pre><code>SELECT id, payload FROM public.mem0_chatstore\nORDER BY id ASC LIMIT 100;\n</code></pre> <p>This will return rows containing the memory text, associated user ID, and metadata such as creation timestamp. Here's an example output:</p> id payload 254218b4-070a-4573-bd54-6a56962ca216 {\"data\": \"Prefers critical reviews about durability\", \"user_id\": \"1\", \"created_at\": \"2025-06-04T00:41:58.613501-07:00\"} 298df4f9-4fcb-409e-858b-66372ef8e0c8 {\"data\": \"Has a deep passion for high-quality audio\", \"user_id\": \"1\", \"created_at\": \"2025-05-29T07:22:05.293070-07:00\"} a3c4ec50-8b0b-46f3-9e85-2e84e2faf805 {\"data\": \"Prefers black color\", \"user_id\": \"1\", \"created_at\": \"2025-05-29T07:22:01.393729-07:00\"} d27e92f0-aff3-4e8f-98eb-7efd1f8e3f69 {\"data\": \"Prefers workout-friendly products\", \"user_id\": \"2\", \"created_at\": \"2025-05-29T07:22:18.402198-07:00\"} <p>Each <code>payload</code> is a JSON object containing a single memory item and the associated user (metadata).</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#behind-the-scenes","title":"Behind the Scenes","text":"<p>While you can add memories manually or programmatically, under the hood <code>mem0</code> uses a large language model (LLM) to extract structured insights\u2014called facts\u2014from user input.</p> <p>These facts are:</p> <ul> <li>Parsed and summarized from free-form user messages (e.g., \u201cI prefer wireless headphones with long battery life.\u201d)</li> <li>Stored with metadata (e.g., user ID, timestamp, hashed ID)</li> <li>Indexed and retrieved later by context-aware agents during personalization</li> </ul> <p>The memory engine acts as a semantic layer, distilling key preferences or intents from conversations and making them accessible to agents without needing to reprocess raw history.</p> <p>\ud83e\udde0 The LLM prompt used for extraction is defined here in the mem0 GitHub repo. You can customize this to fit your domain-specific needs.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/04-Generating-Memories/#summary","title":"Summary","text":"<ul> <li><code>mem0</code> helps agents remember and adapt to individual users.</li> <li>Initial memories are created from CSVs during setup.</li> <li>You can manually add entries and inspect them from the REPL.</li> <li>Live user preferences will be added during interaction with the system.</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/05-Generating-Features-and-Sentiments/","title":"3.5 Generating Features and Sentiments","text":"<p>In this section, you'll explore how the AgenticShop application uses in-database AI to extract valuable insights from raw product reviews.</p> <p>Thanks to the <code>azure_ai</code> extension in Azure Database for PostgreSQL, we can embed powerful language models directly into SQL queries. This enables us to process reviews and identify:</p> <ul> <li>Which product feature a user is talking about</li> <li>What sentiment (positive, negative, or neutral) they express about that feature</li> </ul> <p>These insights help populate the <code>product_reviews</code> table with structured fields like <code>feature_id</code> and <code>sentiment</code>, which downstream agents and search systems rely on.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/05-Generating-Features-and-Sentiments/#try-it-yourself-extract-sentiment-from-a-review","title":"Try It Yourself: Extract Sentiment from a Review","text":"<p>Here\u2019s an example SQL query that demonstrates how we use the <code>azure_ai.extract</code> function to classify sentiment. You can run this using Postgres extension of VS Code to see it in action.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/05-Generating-Features-and-Sentiments/#use-case-sentiment-classification","title":"\ud83d\udccc Use Case: Sentiment Classification","text":"<p>You can run this command using the Postgres Extension to try out generating the sentiment.</p> <p>Query:</p> SQL<pre><code>SELECT azure_ai.extract(\n  'Review: The battery life is incredible.',\n  ARRAY['sentiment - sentiment about the feature as in positive, negative, or neutral'],\n  model =&gt; 'gpt-4o'\n) -&gt;&gt; 'sentiment' AS sentiment;\n</code></pre> <p>Expected Output:</p> Text Only<pre><code>sentiment\n----------\npositive\n</code></pre>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/05-Generating-Features-and-Sentiments/#try-it-yourself-extract-the-product-feature-being-mentioned","title":"Try It Yourself: Extract the Product Feature Being Mentioned","text":"<p>This example shows how to extract which feature is being talked about in the review. We guide the LLM using a schema prompt listing possible feature names.</p> <p>You can run this command using Postgres extension for VS code to try out extracting product feature.</p> <p>Query:</p> SQL<pre><code>SELECT azure_ai.extract(\n  'I love how lightweight and portable this device is.',\n  ARRAY['productFeature: string - A feature of a product. Features should be from: weight, battery life, screen quality, portability or NULL'],\n  model =&gt; 'gpt-4o'\n) -&gt;&gt; 'productFeature' AS extracted_feature;\n</code></pre> <p>Expected Output:</p> Text Only<pre><code>extracted_feature\n--------------------\nportability\n</code></pre> <p>\ud83e\udde0 The AI model picks from the list of feature names you provide in the schema prompt. This is why the feature list is aggregated dynamically in the actual workflow.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/05-Generating-Features-and-Sentiments/#behind-the-scenes","title":"Behind the Scenes","text":"<p>Although you\u2019re testing this manually here, the production system runs these AI queries in batches as part of the data ingestion pipeline using Alembic migrations. During deployment:</p> <ul> <li>Reviews are processed in chunks</li> <li>Each review is paired with the most likely features based on its product</li> <li>The <code>azure_ai.extract()</code> function is used to assign feature IDs and sentiments directly in SQL</li> </ul> <p>This approach keeps everything in-database, minimizing round-trips and making the AI processing fully declarative and observable.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/05-Generating-Features-and-Sentiments/#configurable-execution-for-faster-migrations","title":"Configurable Execution for Faster Migrations","text":"<p>The sentiment and feature extraction runs as part of Alembic migrations using <code>azure_ai.extract()</code> in batch mode. However, to speed up migrations during development or testing, we\u2019ve introduced a feature flag: <code>USE_AZURE_AI_FOR_REVIEWS</code>.</p> <p>When this flag is set to <code>True</code>, reviews are processed using live AI queries.</p> <p>If the flag is <code>False</code> (the default), no AI queries are executed during migration, and instead, the migration loads pre-computed sentiment and feature data from a CSV file.</p> <p>This approach balances the power of in-database AI with flexibility and speed\u2014especially useful for CI pipelines or faster local setup. You can modify this logic in the Alembic migration script if needed.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/06-Building-Graphs/","title":"3.6 Building Graphs for Relationship Insights","text":"<p>To unlock richer, more contextual insights from structured data, AgenticShop uses Apache AGE, a PostgreSQL extension that brings graph database capabilities to relational data. By transforming reviews, products, and features into a graph model, we enable AI agents to perform sophisticated relationship-based queries.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/06-Building-Graphs/#introducing-the-product_review_graph","title":"Introducing the <code>product_review_graph</code>","text":"<p>We define a graph named <code>product_review_graph</code> to model the interconnected nature of product reviews and their associated features. This graph provides the structural foundation for exploratory analysis and downstream AI tasks like recommendation or trend detection.</p> <p>Using Cypher, Apache AGE\u2019s query language, we construct nodes and relationships that mirror how customers discuss products and features in their reviews.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/06-Building-Graphs/#graph-entities-nodes","title":"Graph Entities: Nodes","text":"<p>Each node in the graph represents a distinct type of entity from the underlying database.</p> <ol> <li> <p>Product</p> <ul> <li>Represents a retail product.</li> <li>Properties: <code>id</code>, <code>name</code>, <code>category</code></li> <li> <p>Example:</p> Cypher<pre><code>(p:Product {id: 101, name: \"SmartWatch X200\", category: \"Electronics\"})\n</code></pre> </li> </ul> </li> <li> <p>Review</p> <ul> <li>Captures a user\u2019s review.</li> <li>Properties: <code>id</code>, <code>product_id</code>, <code>feature_id</code>, <code>sentiment</code>, <code>text</code></li> <li>Example:</li> </ul> Cypher<pre><code>(r:Review {id: 5001, text: \"Great battery life!\", sentiment: \"positive\"})\n</code></pre> </li> <li> <p>Feature</p> <ul> <li>Describes a functional or descriptive product attribute.</li> <li>Properties: <code>id</code>, <code>name</code>, <code>categories</code> (JSON array)</li> <li>Example:</li> </ul> Cypher<pre><code>(f:Feature {id: 10, name: \"Battery Life\", categories: [\"Electronics\", \"Wearables\"]})\n</code></pre> </li> </ol>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/06-Building-Graphs/#graph-relationships-edges","title":"Graph Relationships: Edges","text":"<p>Edges define how these entities relate to one another\u2014particularly which products are being reviewed and what sentiments are expressed about specific features.</p> <ol> <li> <p>Product <code>-[HAS_FEATURE]-&gt;</code> Feature</p> <ul> <li>Links a product to its associated features.</li> <li>Example:</li> </ul> Cypher<pre><code>(p:Product)-[:HAS_FEATURE]-&gt;(f:Feature)\n</code></pre> </li> <li> <p>Product <code>-[HAS_REVIEW]-&gt;</code> Review</p> <ul> <li>Connects products to their customer reviews.</li> <li>Example:</li> </ul> Cypher<pre><code>(p:Product)-[:HAS_REVIEW]-&gt;(r:Review)\n</code></pre> </li> <li> <p>Review <code>-[positive_sentiment]-&gt;</code> Feature</p> </li> <li>Review <code>-[negative_sentiment]-&gt;</code> Feature</li> <li> <p>Review <code>-[neutral_sentiment]-&gt;</code> Feature</p> <ul> <li>Connects reviews to features, annotated with the expressed sentiment.</li> <li>Example:</li> </ul> Cypher<pre><code>(r:Review)-[:positive_sentiment {feature_id: 10, product_id: 101}]-&gt;(f:Feature)\n</code></pre> </li> </ol> <p>Each sentiment relationship is directional (from review to feature) and includes metadata like <code>sentiment</code>, <code>product_id</code>, and <code>feature_id</code>.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/06-Building-Graphs/#visualizing-the-graph","title":"Visualizing the Graph","text":"<p>Here\u2019s a simplified schematic of how entities connect:</p> Text Only<pre><code>+-----------+     HAS_FEATURE     +-----------+\n|  Product  |--------------------&gt;|  Feature  |\n+-----------+                     +-----------+\n      |                                 ^\n      |                                 |\n      | HAS_REVIEW                      | positive_sentiment\n      |                                 | negative_sentiment\n      v                                 | neutral_sentiment\n+-----------+                           |\n|  Review   |---------------------------+\n+-----------+\n</code></pre> <p>Diagram Notes</p> <ul> <li>Nodes: Represent real-world concepts: Products, Features, and Reviews.</li> <li>Edges: Capture relationships and sentiment between them.</li> <li>Each edge can carry its own properties, enabling more nuanced filtering and querying.</li> </ul>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/06-Building-Graphs/#from-natural-language-to-graph-query","title":"From Natural Language to Graph Query","text":"<p>Let\u2019s walk through how the graph is used to answer a user query like:</p> <p>\u201cWireless headphones with positive reviews about noise cancellation\u201d</p> <p>This type of question involves multiple steps:</p> <ol> <li> <p>Understanding the product category (\u201cwireless headphones\u201d).</p> </li> <li> <p>Identifying the feature mentioned (\u201cnoise cancellation\u201d).</p> </li> <li> <p>Filtering for positive sentiment from reviews.</p> </li> </ol> <p>To map the user's phrasing of the feature to a canonical feature in our system, we use an LLM-powered feature extraction technique via <code>azure_ai</code>. This helps match varied expressions like \u201cnoise cancellation\u201d to a defined feature (e.g., <code>\"Noise Reduction\"</code>).</p> <p>Here\u2019s the query using azure_ai that performs that step:</p> <p>You can run this command using the Postgres extension of Vscode to try out extracting product feature.</p> SQL<pre><code>WITH feature_schema AS (\n    SELECT\n        'productFeature: string - A feature of a product. Features: ' ||\n        STRING_AGG(fx.feature_name, ', ' ORDER BY fx.feature_name) || ' or NULL' AS feature_schema,\n        ARRAY_AGG(fx.id) AS feature_ids,\n        ARRAY_AGG(fx.feature_name) AS feature_names\n    FROM features fx\n)\nSELECT\n    (azure_ai.extract('{feature_name}', ARRAY[(SELECT feature_schema FROM feature_schema)],\n    '{settings.LLM_MODEL}')::JSONB-&gt;&gt;'productFeature') AS mapped_feature\n</code></pre> <p>Once the feature is resolved, a Cypher query is constructed to count how many positive reviews reference that feature for each product in the given category:</p> SQL<pre><code>SELECT * FROM ag_catalog.cypher('product_review_graph', $$\n    MATCH (p:Product), (f:Feature), (r:Review)\n    WHERE p.id IN {product_ids} AND f.name = '{feature_name}'\n    MATCH (p)-[frel:HAS_FEATURE]-&gt;(f)\n    MATCH (f)&lt;-[rel:{sentiment} {{product_id: p.id}}]-(r)\n    RETURN p.id AS product_id, COUNT(rel) AS positive_review_count\n$$) AS graph_query(product_id agtype, positive_review_count agtype)\nORDER BY (graph_query).positive_review_count DESC;\n</code></pre> <p>This enables the system to rank products like wireless headphones based on the number of positive mentions for the desired feature, surfacing the most well-reviewed products for that specific aspect.</p> <p>This powerful combination of LLM-driven feature resolution and graph traversal using Cypher unlocks complex insights from unstructured user queries\u2014without requiring hardcoded logic or manual keyword mapping.</p>"},{"location":"03-Setting-Up-Data-in-PostgreSQL/07-Resetting-Database/","title":"3.7 Reset Database","text":"<p>The Reset button present on the frontend products page allows users to restore the database to its original post-setup state\u2014i.e., immediately after the application is initialized and migrations are run. It triggers a backend reset endpoint that clears database entries, allowing the application flow to start fresh.</p> <p></p> <p>This reset operation clears all personalized data generated during application usage:</p> <ul> <li>personalized_product_sections table: Stores personalized UI content for each user/product combination. When a user revisits a product, this table is checked first. If personalization exists, it is reused; otherwise, a new personalization flow is triggered. The reset service clears all entries from this table.</li> <li>mem0_chatstore table: Holds user preferences. Initially, it contains predefined preferences added during migrations for all user profiles (Alex, Eugene, Paul). As users interact with the app, additional preferences are stored in this table. The reset service removes preferences added during runtime and restores only the original ones.</li> </ul> <p>This feature ensures a clean testing or demo environment by removing accumulated state while preserving the baseline data defined during setup.</p>"},{"location":"04-Multi-Agent-Workflows/","title":"Multi-Agent System Overview","text":"<p>In this section of the guide, we'll introduce the foundational concepts and architecture behind multi-agent systems using LlamaIndex. These systems consist of multiple specialized agents working collaboratively to solve complex tasks by breaking them down into smaller, manageable parts.</p>"},{"location":"04-Multi-Agent-Workflows/#what-youll-learn","title":"What You'll Learn","text":"<p>This section will help you understand the building blocks of a multi-agent system, how they are coordinated using workflows, and how to implement them using LlamaIndex's flexible, event-driven architecture.</p> <p>You will learn about:</p> <ul> <li>The role of agents in AI-powered applications</li> <li>Events as the primary communication mechanism between agents</li> <li>Workflow structure for organizing agent interactions in a traceable and scalable manner</li> </ul> <p>We will explore how these components are combined to form a structured, reactive pipeline that drives intelligent behavior across the system.</p>"},{"location":"04-Multi-Agent-Workflows/#what-youll-accomplish","title":"What You'll Accomplish","text":"<p>By the end of this section, you will:</p> <ul> <li>Understand how to define and connect agents using LlamaIndex Workflows</li> <li>Review a multi-step agent flow that includes:</li> <li>Planner that breaks down user input into tasks</li> <li>Review Agent that analyzes product reviews using Azure AI</li> <li>Personalization Agent that generates personalized content</li> <li>Evaluation Agent that evaluates the response of other agents (only triggered when <code>Enable Self Correction</code> is set to true from frontend)</li> <li>Presentation Agent that formats results for display</li> <li>Using memory to persist user preferences across sessions</li> </ul> <p>This architecture brings together the full power of LlamaIndex, pg_diskann, Azure AI, mem0, and Apache AGE to support intelligent, explainable, and modular AI behavior within your application.</p>"},{"location":"04-Multi-Agent-Workflows/01-Multi-Agent-Architecture-with-LlamaIndex-Workflows/","title":"4.1 Multi-Agent Architecture with LlamaIndex Workflows","text":"<p>Modern applications powered by Generative AI often require multiple specialized agents working together to solve complex problems. In AgenticShop, we use multi-agent workflows to structure and coordinate tasks such as reviewing product data, updating personalization, performing vector search, and interacting with a user\u2019s memory.</p>"},{"location":"04-Multi-Agent-Workflows/01-Multi-Agent-Architecture-with-LlamaIndex-Workflows/#why-use-a-workflow","title":"Why Use a Workflow?","text":"<p>Multi-agent systems can quickly become unmanageable without structure\u2014agents may step on each other\u2019s toes or miss necessary context. The LlamaIndex <code>Workflow</code> module helps organize these agents into a clear, event-driven pipeline. Each component has a defined role, and execution is coordinated via events that guide the flow of information.</p> <p>Workflows offer the following advantages:</p> <ul> <li>Structured execution: Define how and when each step is triggered.</li> <li>Event-driven orchestration: Steps listen for and emit events to communicate.</li> <li>Composable design: Add, remove, or replace logic easily as your system evolves.</li> <li>Traceability: Workflows can be monitored end-to-end, making debugging easier.</li> </ul> <p>\ud83d\udcda Read more about LlamaIndex Workflows \u2192</p>"},{"location":"04-Multi-Agent-Workflows/01-Multi-Agent-Architecture-with-LlamaIndex-Workflows/#how-it-works","title":"How It Works","text":"<p>At a high level, a LlamaIndex <code>Workflow</code> consists of:</p> <ul> <li>Steps \u2013 These are the individual units of execution in the workflow. Each step performs a specific task and can wrap:</li> <li>An Agent for complex reasoning and multi-turn capabilities</li> <li>A Function for logic such as formatting or transforming data</li> <li>A Tool for invoking structured tools</li> <li>A Router to direct flow based on logic or message content</li> <li>Events \u2013 Events are structured messages that trigger workflow steps. Each step listens for one or more <code>EventType</code>s as input and emits one or more <code>EventType</code>s as output. Events carry the context that allows the workflow to evolve dynamically.</li> <li>Workflow Execution \u2013 Execution starts with <code>workflow.run(input_event)</code>, which dispatches the initial event. From there, steps respond to incoming events, perform their tasks, and emit new events that trigger downstream steps. This event-driven chaining enables flexible, reactive workflows.</li> </ul> <p>Each step is defined with clear input and output events, enabling modular, scalable orchestration of multiple agents and tools.</p>"},{"location":"04-Multi-Agent-Workflows/01-Multi-Agent-Architecture-with-LlamaIndex-Workflows/#what-youll-explore","title":"What You'll Explore","text":"<p>In this guide, you\u2019ll inspect:</p> <ul> <li>A multi-agent <code>Workflow</code> that connects planning, personalization, inventory and presentation logic is already provided.</li> <li>A Review Agent that answers users query based on product reviews.</li> <li>An event-based system where steps react to emitted data rather than executing in a rigid sequence.</li> <li>Integration of memory and retrieval (RAG)</li> </ul> <p>By structuring your agents using LlamaIndex workflows, you'll gain not only modularity and maintainability\u2014but also the ability to scale your application to handle more complex tasks with intelligent orchestration.</p>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/","title":"4.2 Multi-Agent Workflow Implementation","text":"<p>This section provides a deep dive into the multi-agent workflow implemented in AgenticShop. You\u2019ll learn how the architecture ties together multiple specialized agents\u2014each with distinct responsibilities\u2014and how these agents collaborate via LlamaIndex Workflows to personalize product experiences.</p> <p>We\u2019ll walk through:</p> <ul> <li>The overall agent roles</li> <li>A detailed look at the Product Personalization Agent</li> <li>How user memory enhances personalization</li> <li>The anatomy of an agent in our implementation</li> </ul>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/#agent-overview","title":"Agent Overview","text":"<p>The multi-agent system includes the following agents:</p> Agent Description Planner Agent Determines which agents to invoke based on user query and profile. Product Personalization Agent Tailors product descriptions to the user\u2019s preferences. Inventory Agent Analyzes inventory constraints and availability. Reviews Agent Generates response to user queries regarding product reviews. Evaluation Agent Evaluates response of other agents (only triggered when <code>Enable Self Correction</code> is true from frontend. Presentation Agent Synthesizes responses from other agents into a final, user-facing product description. <p>Agents are connected through events and executed via the LlamaIndex <code>Workflow</code> system, which provides modularity, traceability, and event-driven orchestration.</p>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/#example-product-personalization-agent","title":"Example: Product Personalization Agent","text":"<p>Let\u2019s walk through one of the core agents\u2014Product Personalization Agent\u2014and how it operates within the workflow.</p> <p>When triggered, it receives user profile data, product attributes, and product variants. It then uses this context to generate a personalized product summary.</p>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/#event-flow","title":"Event Flow","text":"<ul> <li>Triggered by: <code>ProductPersonalizationEvent</code></li> <li>Returns: <code>ProductPersonalizationCompletedEvent</code></li> </ul> Python<pre><code>result = await self.product_personalization_agent.run(\n    f\"\"\"Personalize the product for user: {user_info},\n    product: {product_info}, product variants: {variants_info}\"\"\",\n    timeout=settings.PRODUCT_PERSONALIZATION_AGENT_TIMEOUT,\n)\n</code></pre> <p>If the agent fails to respond within the timeout, a fallback message is returned to ensure the workflow continues.</p>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/#anatomy-of-an-agent","title":"Anatomy of an Agent","text":"<p>Agents in AgenticShop are implemented using LlamaIndex\u2019s <code>FunctionAgent</code>. Each agent wraps a system prompt and has a clear role.</p> <p>Here\u2019s how the Product Personalization Agent is defined:</p> Python<pre><code>return FunctionAgent(\n    name=AgentNames.PRODUCT_PERSONALIZATION_AGENT.value,\n    description=(\n        \"Analyzes user profiles and product data to highlight features most relevant to individual preferences.\"\n    ),\n    llm=llm,\n    system_prompt=PRODUCT_PERSONALIZATION_AGENT_PROMPT,\n    tools=[],\n    allow_parallel_tool_calls=False,\n    verbose=settings.VERBOSE,\n)\n</code></pre>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/#where-to-find-system-prompts","title":"Where to Find System Prompts","text":"<p>All system prompts for these agents are defined in:</p> Bash<pre><code>backend/src/agents/prompts.py\n</code></pre> <p>You can modify the tone, structure, or output expectations of each agent by editing the associated prompt in this file.</p>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/#memory-integration","title":"Memory Integration","text":"<p>The system uses <code>mem0</code> to personalize interactions based on user memory. Here\u2019s how memory contributes:</p> <ul> <li>During workflow setup, user preferences are retrieved from memory and included in the profile.</li> <li>If a user adds new input (e.g., \"I care about portability\"), it\u2019s stored back to memory.</li> <li>Memory influences agent outputs like personalization.</li> </ul>"},{"location":"04-Multi-Agent-Workflows/02-Multi-Agent-Workflow-Implementation/#memory-update-example","title":"Memory Update Example","text":"Python<pre><code>results = self.memory.add(messages=user_msg, user_id=str(user_id))\n</code></pre> <p>These updates are stored in PostgreSQL under the <code>mem0_chatstore</code> table.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/","title":"4.3. AgenticShop Flow Walkthrough","text":"<p>In this section, you'll walk through a real user interaction scenario powered by our multi-agent architecture. This flow highlights how a user query triggers intelligent agentic behavior involving vector search, planning, personalization, and inventory checking.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/#1-open-the-app","title":"1. Open the App","text":"<p>Open the URL http://localhost:5173/ to access the web interface. You\u2019ll be greeted with the homepage of the AgenticShop frontend.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/#2-select-a-profile","title":"2. Select a Profile","text":"<p>You\u2019ll see three predefined user profiles on the landing screen. Each profile is configured with different preferences.</p> <p></p> <p>Select any user profile. You will be taken to the product listing page, where a set of products are displayed.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/#3-search-for-wireless-headphones","title":"3. Search for \"Wireless headphones\"","text":"<p>In the search bar, enter a query like:</p> Text Only<pre><code>Wireless headphones\n</code></pre> <p></p> <p>Behind the scenes a vector search is performed using pg_diskann to fetch the most relevant products. We will explore more on the query routing in the following section.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/#4-background-personalization","title":"4. Background Personalization","text":"<p>Each returned product triggers a background multi-agent workflow that personalizes the product description based on the selected user\u2019s profile.</p> <p>This proactive triggering improves UX by hiding the latency of the multi-agent system.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/#5-open-a-product-detail-page","title":"5. Open a Product Detail Page","text":"<p>Click on the first product to open its detail page. You\u2019ll now see a section titled \"Your Personalized Section\".</p> <p></p> <p>This personalized content is generated based on the profile selected earlier.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/#6-review-the-agentic-flow","title":"6. Review the Agentic Flow","text":"<p>Open the Agentic Flow panel.</p> <p>You\u2019ll see:</p> <ul> <li>Planning Agent: Determines which agents to invoke</li> <li>Inventory Agent: Checks if the product is in stock</li> <li>Product Personalization Agent: Tailors the content</li> <li>Presentation Agent: Synthesizes final response</li> </ul> <p></p> <p>Click through each tab to review the input and output of each agent involved in the workflow.</p> <p>In a later section, we will walkthrough the code base and show how the reviews agent is added to the mix.</p>"},{"location":"04-Multi-Agent-Workflows/03-AgenticShop-Walkthrough/#7-trigger-personalization-and-memory-update","title":"7. Trigger Personalization and Memory Update","text":"<p>Now let\u2019s walk through how user preferences are updated and persisted using memory, making future responses more tailored and consistent.</p> <p>In the input box on the product detail page, type the following query:</p> Text Only<pre><code>Always show if red color is available in stock\n</code></pre> <p>This query performs two key actions in the backend:</p> <ul> <li> <p>Personalization Update:    It triggers the multi-agent personalization workflow again, but this time the personalization is adapted to explicitly include whether the red color variant is available. The following image shows that Red color is not available for this product as part of the Inventory Agents output.</p> <p></p> </li> <li> <p>Memory Storage via mem0:    The system uses mem0 to store this preference as part of your user profile. This means that for any future product interactions, the agent will automatically consider your preference for the red color\u2014without requiring you to re-enter it. You will see a \"Memory updated!\" toast message whenever memory is updated. </p> </li> </ul> <p>You can inspect this memory update by opening the Agentic Flow panel and checking the Planning Agent tab.</p> <p></p> <p>In the next section, we\u2019ll extend this capability by introducing an agent that reasons over product reviews\u2014making your experience even richer.</p>"},{"location":"04-Multi-Agent-Workflows/04-Command-Routing-Agent/","title":"4.4 Tool-Enabled Agent: Intelligent Query Router","text":"<p>In this section, we explore a powerful enhancement to our multi-agent setup\u2014introducing the Command Routing Agent, an agent equipped with multiple tools. Unlike earlier agents that perform a single role, this one unifies multiple capabilities under a single interface, allowing it to dynamically respond to different types of user queries.</p> <p>Where previous agents handled focused tasks like personalization or inventory lookup, this agent handles broader input and delegates work to appropriate tools (including triggering the workflow we discussed in previous section).</p> <p>You can expand the section below to review the prompt and declaration of Command Routing Agent.</p> <p>To review the full implementation visit this file <code>backend/src/agents/user_query_agent.py</code></p> Query Agent Prompt and Declaration backend/src/agents/user_query_agent.py<pre><code>USER_QUERY_AGENT_PROMPT = \"\"\"\n    You are a helpful AI assistant designed to assist users with their queries or product searches\n    by intelligently selecting and invoking exactly ONE of the following tools:\n\n    1. `query_about_product`: Use this when the user is asking about a specific product\n    or seeking information based on an already selected product.\n    - Example: \"Show me a summary of critical reviews about durability.\"\n\n    2. `query_reviews_with_sentiment`: Use this when the user's query includes *search keywords* and\n    mentions *review sentiments* or *specific features mentioned in reviews*.\n    - Example: \"Water-resistant headphones with positive reviews about noise cancellation.\"\n\n    3. `search_products`: Use this when the user is expressing a search intent without referencing reviews or sentiment.\n    - Example: \"Water-resistant headphones.\"\n\n    **Instructions:**\n    - Identify the user's intent and call only ONE tool accordingly.\n    - DO NOT generate a response yourself.\n    - DO NOT ask the user for clarification.\n    - If the intent is unclear or ambiguous, default to using `query_about_product`.\n    - Return only the output of the called tool\u2014do not modify or paraphrase it.\n\n    Be precise. Your role is to route the query to the correct tool, not to interpret or summarize the output.\n    \"\"\"\n# Initialize Command Routing Agent\nFunctionAgent(\n    name=AgentNames.USER_QUERY_AGENT.value,\n    description=\"Acts as a smart router that interprets user queries and directs them to the most appropriate tool.\",\n    system_prompt=USER_QUERY_AGENT_PROMPT,\n    tools=self._get_tools(),\n    llm=self.llm,\n    verbose=settings.VERBOSE,\n)\n</code></pre>"},{"location":"04-Multi-Agent-Workflows/04-Command-Routing-Agent/#query-routing-tools","title":"Query Routing Tools","text":"<p>The Command Routing Agent is initialized with three tools:</p> Tool Name Purpose <code>query_about_product</code> Triggers the multi-agent personalization workflow for the current user <code>search_products</code> Performs a vector search over product embeddings <code>query_reviews_with_sentiment</code> Combines sentiment and feature filters to search reviews graphically <p>These tools are defined as callable Python functions and wrapped into LlamaIndex <code>FunctionTool</code> objects. The agent then uses the LLM to choose the correct tool based on user intent.</p> Python<pre><code>FunctionAgent(\n    name=\"user_query_agent\",\n    description=\"Smart router that interprets user queries and directs them to the most appropriate tool.\",\n    system_prompt=USER_QUERY_AGENT_PROMPT,\n    tools=[...],  # Three tool functions\n    llm=llm,\n    verbose=settings.VERBOSE,\n)\n</code></pre>"},{"location":"04-Multi-Agent-Workflows/04-Command-Routing-Agent/#how-it-works","title":"How It Works","text":"<p>When a query reaches this agent, here\u2019s the high-level flow:</p> <ol> <li>LLM Reasoning: The LLM receives the user query and system prompt. Based on the tool metadata, it selects the most relevant tool to invoke.</li> <li>Tool Invocation: The corresponding Python function is executed:</li> <li>For sentiment-based queries, it performs a vector + graph query.</li> <li>For general product searches, it uses embedding search.</li> <li>For personalization flows, it dispatches a background multi-agent workflow.</li> <li>Streaming Response: Each tool emits events back to the frontend via a message queue for real-time updates.</li> </ol> <p>This setup demonstrates how a single LLM-powered agent can identify user intent in real time and route the query to the most appropriate tool, enabling more natural interactions and unlocking dynamic, intent-driven experiences.</p>"},{"location":"04-Multi-Agent-Workflows/04-Command-Routing-Agent/#smart-query-routing-in-action","title":"Smart Query Routing in Action","text":"<p>Let\u2019s walk through how the Command Routing Agent intelligently routes different types of user inputs to the right tool.</p> <p>Each of the following steps can be tried directly in the product listing or detail page.</p>"},{"location":"04-Multi-Agent-Workflows/04-Command-Routing-Agent/#1-search-for-a-product-category","title":"1. Search for a Product Category","text":"<p>In the product listing page, enter a query like:</p> Text Only<pre><code>Waterproof headphones\n</code></pre> <p>The Command Routing Agent will receive this query and determine that the best tool is <code>search_products</code>.</p> <p>This performs a vector search over the product embeddings using <code>pg_diskann</code>. To see which tool has been triggered, open the Agentic Flow panel.</p> <p></p>"},{"location":"04-Multi-Agent-Workflows/04-Command-Routing-Agent/#2-ask-for-sentiment-based-feedback","title":"2. Ask for Sentiment-Based Feedback","text":"<p>Now either from the listing page, or the product detail page try the following query:</p> Text Only<pre><code>wireless headphones with good noise cancellation\n</code></pre> <p>This time, the agent identifies that your query is about review sentiment about a particular product feature and triggers the <code>query_reviews_with_sentiment</code> tool. The product which has the most positive reviews about the requested feature is gets listed on the top. These reviews can be viewed on each product page.</p> <p>This combines the power of different Postgres extensions to perform semantic search (via pg_diskann), feature extractions (using azure_ai), and graph queries (using age) to return results.</p>"},{"location":"04-Multi-Agent-Workflows/04-Command-Routing-Agent/#3-trigger-a-multi-agent-workflow","title":"3. Trigger a Multi-Agent Workflow","text":"<p>Lastly the third tool that the Command Routing Agent supports is <code>query_about_product</code>. To trigger this, click on a product to open its detail page. Then, enter a query like:</p> Text Only<pre><code>Always show if red color is available in stock\n</code></pre> <p>The agent now routes the query to the <code>query_about_product</code> tool, which kicks off the multi-agent personalization workflow.</p> <p>This flow involves the planning, inventory, personalization, and presentation agents, just like the earlier walkthrough.</p> <p>These examples demonstrate how the Command Routing Agent interprets natural language, identifies intent, and delegates the task to the appropriate specialized tool\u2014enhancing flexibility and user experience without requiring separate agents for each task.</p> <p>Why Some Queries May Show General Results</p> <p>When the <code>query_reviews_with_sentiment</code> tool is invoked but no matching feature mapping exists in the database\u2014such as when there are no reviews or the requested feature is not associated with any products\u2014the agent automatically falls back to a general vector search within the relevant category. In this case, a notification is displayed to inform the user that sentiment-based results were unavailable, and general product results are being shown instead.</p> <p>You can review all available categories (\"Headphones\", \"Tablets\", \"Smartwatches\") and features in this file <code>backend/data/product_features.csv</code></p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/","title":"4.5 \ud83d\udd0d Understanding What Queries Work (and Why)","text":"<p>Your personalized shopping assistant supports product search and recommendation for a limited dataset. To ensure relevant results, it\u2019s important to understand how the system interprets queries, and why some may fail.</p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#supported-product-categories","title":"Supported Product Categories","text":"<p>The dataset used in this solution contains product information and customer reviews from only three product categories:</p> <ul> <li>Smartwatches</li> <li>Headphones</li> <li>Tablets</li> </ul> <p>Any query that refers to a product outside these categories (e.g., \"laptops\", \"TVs\", \"keyboards\") will not return results.</p> <p>What features are supported for each category?</p> <p>\"You can review all available categories (\"Headphones\", \"Tablets\", \"Smartwatches\") and features in this file <code>backend/data/features.csv</code>\"</p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#query-types-and-tools","title":"\ud83d\udd0e Query Types and Tools","text":"<p>We support two types of search-powered queries using the following tools:</p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#standard-vector-search","title":"Standard Vector Search","text":"<ul> <li>Used for general product discovery queries, such as:</li> <li>\"Wireless earbuds\"</li> <li>\"Smartwatch with fitness tracker\"</li> <li>Powered by pg_diskann-based vector search, which retrieves the most semantically relevant products based on product descriptions and specs.</li> <li>Internally, the system tries to infer the product category from the query (e.g., \"earbuds\" maps to Headphones). If the LLM fails to map the query to one of the 3 valid categories, no results will be returned.</li> </ul>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#sentiment-aware-search","title":"Sentiment-Aware Search","text":"<ul> <li>Used for feature-based discovery with sentiment, such as:</li> <li>\"Find headphones with great noise cancellation\"</li> <li>\"Tablets with reliable cellular connectivity\"</li> <li>This tool combines:</li> <li>Vector search</li> <li>Azure AI-powered sentiment analysis and feature extraction</li> <li>The system tries to map:<ol> <li>The product category (same limitations apply as above).</li> <li>The product feature mentioned in the query.</li> </ol> </li> </ul> <p>If the mentioned feature is not tracked in our dataset, the query won\u2019t work.</p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#example-that-will-fail","title":"\u274c Example that will fail","text":"<p>\"Smartwatch with great battery life\"</p> <p>Why it might fail:</p> <ul> <li>The feature (e.g., battery life) is not one of the predefined features available for extraction.  </li> <li>The feature may be mentioned in user reviews, but it\u2019s not mapped to any known feature in our system.  </li> <li>The feature may be extracted and mapped to some products, but the associated sentiment might not be positive in any of the reviews.</li> <li>The product may include the feature, but if it's not mentioned in reviews, it won\u2019t be surfaced through sentiment-based extraction.</li> </ul>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#flexible-matching","title":"Flexible Matching","text":"<p>The feature name in the query doesn\u2019t need to be an exact match. The system can handle close variations and synonyms:</p> <ul> <li>\"Headphones with great active noise cancellation\"</li> <li>\"Headphones with great ANC\"</li> <li>\"Headphones with great noise cancellation\"</li> </ul> <p>All will map to the tracked feature Noise Cancellation</p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#note-on-review-coverage","title":"\ud83d\udccc Note on Review Coverage","text":"<p>Even if the feature is supported, relevant reviews must exist for the system to extract sentiment. If no reviews discuss a feature for a product, it won't affect ranking.</p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#sample-queries-that-work","title":"\ud83e\uddea Sample Queries That Work","text":"<p>Here are examples of queries that work well with each tool supported in the assistant. These examples can help you test and understand the system behavior.</p>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#product-specific-query-handling","title":"Product-Specific Query Handling","text":"<p>Used when the user is already on a product page and refers to that product directly.</p> <p>Example Queries:</p> <ul> <li>\"Show critical reviews about durability\"</li> <li>\"Always show a summary of critical reviews\"</li> <li>\"What do users dislike about this smartwatch\"</li> <li>\"What do people say about its battery life\"</li> <li>\"Is this product available in black\"</li> <li>\"Always highlight the products availability in red\"</li> </ul>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#standard-vector-search_1","title":"Standard Vector Search","text":"<p>Used for general product discovery, especially when the user doesn't specify detailed preferences.</p> <p>Example Queries:</p> <ul> <li>\"Wireless headphones\"</li> <li>\"Tablets with camera\"</li> <li>\"Waterproof smartwatches\"</li> <li>\"Tablets with HD display\"</li> <li>\"Smartwatches with step tracking\"</li> <li>\"Headphones for workout\"</li> </ul>"},{"location":"04-Multi-Agent-Workflows/05-Understanding-What-Queries-Work/#sentiment-aware-search_1","title":"Sentiment-Aware Search","text":"<p>Used when the user expresses sentiment or preference toward specific product features.</p> <p>Example Queries:</p> <ul> <li>\"Headphones with great noise cancellation\"</li> <li>\"Smartwatches with accurate heart rate monitoring\"</li> <li>\"Top tablets with strong parental controls\"</li> <li>\"Smartwatches with reliable sleep tracking\"</li> <li>\"Headphones with average ANC\"</li> </ul>"},{"location":"05-Agent%20Architecture%20and%20Integration/","title":"Agent Architecture and Integration: Guide Overview","text":"<p>Welcome to \"Agent Architecture and Integration\"! In this guide, you'll get an in-depth overview of how the Reviews Agent is integrated within the multi-agent system. This section explains the architecture, implementation, and codebase details, so you can understand how the agent operates and interacts with other components in the system.</p> <p>By the end of this guide, you'll understand:</p> <ul> <li>How a specialized agent prompt is designed</li> <li>How agents are integrated into the planning and presentation layers</li> <li>How new agents are registered in code</li> <li>How agents connect to vector stores and query engines</li> <li>How LlamaIndex workflows enable event-driven orchestration</li> <li>How agents participate in multi-step, multi-agent flows</li> </ul> <p>Here's what is involved, step by step:</p> <ol> <li>Reviews Agent Prompt: How the prompt is crafted to generate insightful, user-focused review summaries.</li> <li>Planning Agent Integration: How the Reviews Agent is made discoverable and selectable by the system's planner.</li> <li>Presentation Agent Integration: How the agent is surfaced in the presentation layer.</li> <li>Reviews Agent Definition: The core logic for the agent, including connections to vector stores and query engines.</li> <li>Reviews Events: The events that trigger and track the agent's actions.</li> <li>MultiAgentFlow Integration: How the agent is incorporated into the event-driven workflow for seamless collaboration.</li> <li>Workflow Service Integration: How the agent is wired into the workflow service for full</li> </ol> <p>Let's deep dive into the implementation and code-level details to understand how the Reviews Agent operates within the multi-agent system.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/01-reviews-agent-prompt/","title":"5.1: Reviews Agent Prompt","text":"<p>This section provides an overview of the prompt defined for the Reviews Agent in <code>backend/src/agents/prompts.py</code>. The prompt instructs the agent on how to analyze and summarize product reviews, ensuring the output is concise, relevant, and structured.</p> <p>File location: <code>backend/src/agents/prompts.py</code></p> <p>Purpose: This prompt guides the Reviews Agent to generate concise, relevant, and structured summaries of product reviews, ensuring the output is always a JSON object with a summary and reasoning.</p> <p>Below is the prompt as implemented in the codebase:</p> Python<pre><code>REVIEWS_AGENT_PROMPT = \"\"\"\nYou are an assistant specializing in analyzing and summarizing product reviews.\nYour task is to:\n- Use the provided tools to query and retrieve product reviews.\n- Summarize the insights from reviews that are most relevant to the user's preferences and optional user query.\nInstructions:\n- The review summary must be concise, clear, and engaging.\n- The summary should be a maximum of 3 sentences \u2014 not in bullet points.\n- Focus on capturing the sentiments, highlights, or issues that are most aligned with the user's stated preferences.\n- Base your summary strictly on the information provided by the tools; do not introduce external knowledge.\n- DO NOT summarize the user's preferences themselves as the summary, make sure you are talking about the product.\n- Do not include internal IDs, database field names, metadata, or any irrelevant information in the output.\n- When generating summary, focus only on those user preferences that are relevant to this product or product category.\nFor example, if audio quality is not relevant to smartwatch then don't talk about it.\n- If there is any preference or user query related to reviews,\nthat should always take precedence when talking about the reviews and should be the focus of the summary.\nReasoning:\n- Provide a list of short explanations, each describing why a particular review insight was included in the summary.\n- Each list item should clearly reference user preferences or key review insights without describing the full thought process.\nOutput:\n- STRICTLY output only a raw JSON object \u2014 no Markdown, no formatting, no additional text.\n- Do NOT include any code blocks or backticks.\n- Do NOT return markdown.\nThe JSON must follow this structure:\n{\n  \"review_summary\": \"Concise review summary text\",\n  \"reasoning\": [\n    \"Short reason 1 for including a review point.\",\n    \"Short reason 2 for another review point.\"\n  ]\n}\n\"\"\"\n</code></pre> <p>What this does:</p> <p>This prompt guides the Reviews Agent to generate concise, relevant, and structured summaries of product reviews, ensuring the output is always a JSON object with a summary and reasoning.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/02-reviews-agent-definition/","title":"5.2: Reviews Agent Definition","text":"<p>This section provides an overview of how the Reviews Agent is defined in the codebase (<code>backend/src/agents/reviews_agent.py</code>). The agent is set up to use a vector store and LLM to retrieve and summarize product reviews.</p> <p>File location: <code>backend/src/agents/reviews_agent.py</code></p> <p>Purpose: Encapsulates all logic for the Reviews Agent, making it reusable and easy to maintain.</p> <p>Below is the code that defines the Reviews Agent:</p> Python<pre><code>from llama_index.core import VectorStoreIndex\nfrom llama_index.core.agent.workflow import FunctionAgent\nfrom llama_index.core.base.embeddings.base import BaseEmbedding\nfrom llama_index.core.base.llms.base import BaseLLM\nfrom llama_index.core.tools import QueryEngineTool, ToolMetadata\nfrom llama_index.core.vector_stores.types import (\n    BasePydanticVectorStore,\n    MetadataFilters,\n)\nfrom src.agents.prompts import REVIEWS_AGENT_PROMPT\nfrom src.config.config import settings\nfrom src.schemas.enums import AgentNames\n\n\ndef get_reviews_agent(\n    llm: BaseLLM,\n    embed_model: BaseEmbedding,\n    vector_store: BasePydanticVectorStore,\n    filters: MetadataFilters,\n):\n    \"\"\"\n    Create and return a Reviews Agent for summarizing product reviews.\n    Args:\n        llm: The language model to use.\n        embed_model: The embedding model for vector search.\n        vector_store: The vector store containing review embeddings.\n        filters: Metadata filters for narrowing search results.\n    Returns:\n        Configured FunctionAgent for product review summarization.\n    \"\"\"\n\n    # 1. Create an index from the vector store\n    index = VectorStoreIndex.from_vector_store(\n        vector_store=vector_store,\n        embed_model=embed_model,\n    )\n\n    # 2. Create a query engine for searching and summarizing reviews\n    query_engine = index.as_query_engine(\n        similarity_top_k=settings.TOP_K,\n        verbose=settings.VERBOSE,\n        use_async=True,\n        llm=llm,\n        filters=filters,\n    )\n\n    # 3. Wrap the query engine as a tool for the agent\n    query_engine_tools = [\n        QueryEngineTool(\n            query_engine=query_engine,\n            metadata=ToolMetadata(\n                name=\"product_reviews_summarization\",\n                description=(\n                    \"Retrieves, summarizes and answers questions about customer reviews for a specified product.\"\n                ),\n            ),\n        ),\n    ]\n\n    # 4. Create and return the FunctionAgent\n    return FunctionAgent(\n        name=AgentNames.REVIEWS_AGENT.value,\n        llm=llm,\n        tools=query_engine_tools,\n        verbose=settings.VERBOSE,\n        allow_parallel_tool_calls=False,\n        system_prompt=REVIEWS_AGENT_PROMPT,\n    )\n</code></pre> <p>What this does:</p> <p>This code defines the Reviews Agent, which uses a vector store and LLM to retrieve and summarize product reviews. It exposes a function to create and configure the agent.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/02-reviews-agent-definition/#exposing-the-agent-in-the-module","title":"Exposing the Agent in the Module","text":"<p>The <code>get_reviews_agent</code> function is imported and exposed in <code>backend/src/agents/__init__.py</code>, making it available for use throughout the codebase.</p> <p>File location: <code>backend/src/agents/__init__.py</code></p> <p>Purpose: Registers the agent so it can be easily imported and used in other modules.</p> <p>Example of how the agent is exposed:</p> Python<pre><code>from .reviews_agent import get_reviews_agent\n\n__all__ = [\n    \"get_presentation_agent\",\n    \"get_product_personalization_agent\",\n    \"get_inventory_agent\",\n    \"get_planning_agent\",\n    \"get_reviews_agent\",\n]\n</code></pre> <p>What this does:</p> <p>This makes the <code>get_reviews_agent</code> function available for import elsewhere in your codebase.</p> <p>Additional Explanation:</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/02-reviews-agent-definition/#vector-stores","title":"Vector Stores","text":"<p>A vector store is a storage system that holds embedding vectors of document chunks (and sometimes the document chunks themselves). When you ingest documents, they are split into smaller pieces (chunks), and each chunk is converted into a vector using an embedding model. These vectors are then stored in the vector store, enabling efficient similarity search and retrieval.</p> <p>In the code, a vector store is used to store and retrieve product review embeddings. This allows the agent to efficiently find and retrieve relevant review chunks based on the user\u2019s query and preferences.</p> <p>For more details, see the LlamaIndex documentation on Vector Stores.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/02-reviews-agent-definition/#query-engine","title":"Query Engine","text":"<p>A query engine is a generic interface in LlamaIndex that allows you to ask questions over your data. It takes a natural language query and returns a rich response, often by retrieving relevant chunks from one or more indexes (such as a vector store) and generating an answer using an LLM. Query engines can be composed to provide more advanced capabilities.</p> <p>In the code, a query engine is created from the vector store index. This query engine is configured to use the LLM, embedding model, and filters, and is responsible for retrieving the most relevant product review chunks and generating a summary or answer based on them.</p> <p>For more details, see the LlamaIndex documentation on Query Engine.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/02-reviews-agent-definition/#query-engine-tool","title":"Query Engine Tool","text":"<p>A Query Engine Tool is a wrapper that allows a query engine to be used as a tool within an agent workflow. It provides metadata (such as a name and description) and exposes the query engine\u2019s capabilities to the agent, so the agent can invoke it as needed.</p> <p>In the code, the query engine is wrapped in a <code>QueryEngineTool</code>, providing it with a name and description. This tool is then passed to the agent, enabling the agent to use the query engine to retrieve and summarize product reviews as part of its workflow.</p> <p>For more details, see the LlamaIndex documentation on Query Engine Tools.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/03-planning-agent-prompt/","title":"5.3 Planning Agent Prompt","text":"<p>This section provides an overview of how the <code>PLANNING_AGENT_PROMPT</code> is structured to include the Reviews Agent in the planning and agent selection logic.</p> <p>File location: <code>backend/src/agents/prompts.py</code></p> <p>Purpose: Ensures the planner is aware of the Reviews Agent and can suggest it for relevant user queries.</p> <p>The prompt includes a description of the Reviews Agent under the section that begins with \"Following agents are available:\"</p> Python<pre><code>\"\"\"\n- Reviews Agent: Answer queries related to product reviews. Can be used to generate personalized\n  content related to product reviews. Invoke if user is interested in reviews.\n\"\"\"\n</code></pre> <p>The JSON agents list in the planning agent prompt is also updated:</p> Python<pre><code>\"Respond with a JSON list of agents to call: [\"product_personalization\", \"reviews\", \"inventory\"]\"\n</code></pre> <p>The updated prompt looks like this:</p> Python<pre><code>PLANNING_AGENT_PROMPT = \"\"\"\nGiven a user profile, and optional user query, your task is to determine which specialized agents should be invoked as part\nof an agentic workflow to personalize the product information section of an ecommerce page.\n\nFollowing agents are available:\n  - Product Personalization Agent: Analyzes the users profile and then suggests the features of the product that match\n    the users profile and create customized description of the product based on the user profile.\n  - Inventory Agent: Checks availability and related options based on users preference. Invoke if user\n    has certain preferences that can be checked against the product inventory.\n  - Reviews Agent: Answer queries related to product reviews. Can be used to generate personalized\n    content related to product reviews. Invoke if user is interested in reviews.\n\nOnly include agents that would provide value given the context.\nRespond with a JSON list of agents to call: [\"product_personalization\", \"reviews\", \"inventory\"]\" and\ndon\u2019t include any code blocks or backticks.\n\"\"\"\n</code></pre> <p>What this does:</p> <p>This prompt structure ensures the planning agent is aware of the Reviews Agent and can include it in its planning and agent selection logic.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/04-presentation-agent-prompt/","title":"5.4 Presentation Agent Prompt","text":"<p>This section provides an overview of how the <code>PRESENTATION_AGENT_PROMPT</code> lists the Reviews Agent as one of the available agents. This makes the Reviews Agent visible to the presentation layer, allowing it to be referenced.</p> <p>File location: <code>backend/src/agents/prompts.py</code></p> <p>Purpose: Ensures the Reviews Agent is discoverable and selectable in the UI or any presentation layer.</p> Python<pre><code>Agents:\n- Product Personalization Agent\n- Inventory Agent\n- Reviews Agent\n</code></pre> <p>What this does:</p> <p>This makes the Reviews Agent visible to the presentation layer, allowing it to be referenced and invoked</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/05-multiagent-class-integration/","title":"5.5: MultiAgentFlow Class Integration","text":""},{"location":"05-Agent%20Architecture%20and%20Integration/05-multiagent-class-integration/#understanding-multiagent-architecture-using-llamaindex-workflows","title":"Understanding MultiAgent Architecture Using LlamaIndex Workflows","text":"<p>LlamaIndex workflows are designed around an event-driven architecture. The workflow begins when a start event is triggered. Each step in the workflow is defined by a function decorated with the <code>@step</code> decorator. These step functions are activated by specific event types, which means the workflow decides which step to execute next based on the event it receives.</p> <p>Each step processes its input event and returns a new event. This returned event determines the next step in the workflow. Steps can emit multiple events, and a single step can be set up to listen for several different event types. This flexibility allows multiple steps to run in parallel, enabling efficient and scalable workflows.</p> <p>In the context of multi-agent systems, each step typically interacts with a different agent. By leveraging this event-driven approach, several agents can run at the same time, making the workflow both modular and highly parallelized. This structure makes it easy to add, remove, or modify agents as your application evolves.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/05-multiagent-class-integration/#reviews-events","title":"Reviews Events","text":"<p>The <code>ReviewsEvent</code> and <code>ReviewsCompletedEvent</code> classes in <code>multi_agent_workflow.py</code> handle events related to the Reviews Agent. These event classes allow the workflow to track and manage the execution and completion of the Reviews Agent.</p> <p>File location: <code>backend/src/agents/multi_agent_workflow.py</code> (or wherever your workflow/event classes are defined)</p> <p>Purpose: These classes represent the start and completion of a review agent task, enabling event-driven orchestration in your workflow.</p> Python<pre><code>class ReviewsEvent(Event):\n    pass\n\nclass ReviewsCompletedEvent(Event):\n    result: str\n</code></pre> <p>What this does:</p> <p>These event classes allow the workflow to track and manage the execution and completion of the Reviews Agent.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/05-multiagent-class-integration/#reviews-agent-integration-in-multiagentflow-class","title":"Reviews Agent Integration in MultiAgentFlow Class","text":"<p>The <code>MultiAgentFlow</code> class is updated to accept the Reviews Agent, emit and handle review events, and add a step function for the Reviews Agent. This integrates the Reviews Agent into the multi-agent workflow, allowing it to be triggered, run, and its results to be handled like other agents.</p> <p>File location: <code>backend/src/agents/multi_agent_workflow.py</code></p> <p>Purpose: This integration wires the Reviews Agent into the event-driven workflow, so it can be triggered, run, and its results handled like any other agent.</p> <p>The constructor of the MultiAgentFlow class includes the Reviews Agent:</p> Python<pre><code>def __init__(\n    self,\n    db: AsyncSession,\n    product_personalization_agent: BaseAgent,\n    inventory_agent: BaseAgent,\n    presentation_agent: BaseAgent,\n    planning_agent: BaseAgent,\n    reviews_agent: BaseAgent,\n    memory: Memory,\n    message_queue: Optional[asyncio.Queue] = None,\n    fault_correction: bool = False,\n    **kwargs,\n):\n    self.db = db\n    self.product_personalization_agent = product_personalization_agent\n    self.inventory_agent = inventory_agent\n    self.presentation_agent = presentation_agent\n    self.planning_agent = planning_agent\n    self.reviews_agent = reviews_agent\n    self.memory = memory\n    self.message_queue = message_queue\n    self.fault_correction = fault_correction\n\n    super().__init__(**kwargs)\n</code></pre> <p>Any type of event that a step function can emit must be mentioned in its return type. <code>ReviewsEvent</code> is included so it can be triggered by the planning agent.</p> <p>The planning step function signature:</p> Python<pre><code>@step\nasync def planning(\n    self,\n    ctx: Context,\n    ev: StartEvent,\n) -&gt; ProductPersonalizationEvent | InventoryEvent | ReviewsEvent:\n</code></pre> <p>The planning step includes conditional logic based on the output of the planning agent. This logic determines which step to trigger next. To support the Reviews Agent, the logic can trigger the Reviews Agent when appropriate:</p> Python<pre><code>if \"product_personalization\" in agents_to_call:\n    ctx.send_event(ProductPersonalizationEvent())\n    triggered_agents.append(ProductPersonalizationCompletedEvent)\nif \"inventory\" in agents_to_call:\n    ctx.send_event(InventoryEvent())\n    triggered_agents.append(InventoryCompletedEvent)\nif \"reviews\" in agents_to_call:\n    ctx.send_event(ReviewsEvent())\n    triggered_agents.append(ReviewsCompletedEvent)\n</code></pre> <p>The review agent step function is executed when the ReviewsEvent is emitted. Within this, the review agent defined in <code>agents/reviews_agent.py</code> is called:</p> Python<pre><code>@step\nasync def review(\n    self,\n    ctx: Context,\n    ev: ReviewsEvent,\n) -&gt; ReviewsCompletedEvent:\n    \"\"\"\n    Handles the review event by running the Reviews Agent and returning the result.\n    \"\"\"\n    user_info = await ctx.get(\"user_profile\")\n    user_message = await ctx.get(\"user_msg\")\n\n    try:\n        prompt = textwrap.dedent(\n            f\"\"\"\n            Generate a summary of relevant reviews of the product based on the\n            user's preferences: {user_info['user_preferences']}\n            and the optional user query: {user_message}.\n        \"\"\",\n        )\n\n        logger.info(f\"Review Prompt: {prompt}\")\n\n        result = await self.reviews_agent.run(\n            prompt,\n            timeout=settings.REVIEW_AGENT_TIMEOUT,\n        )\n\n    except WorkflowTimeoutError:\n        logger.info(\"Review Agent has timed out.\")\n        result = \"Review agent timed out. No response\"\n\n    return ReviewsCompletedEvent(result=str(result))\n</code></pre> <p>The presentation agent accepts the outputs of agents and then refines them before eventually passing them to the frontend. The presentation step function accepts the output of the review agent step function:</p> Python<pre><code>@step\nasync def presentation(\n    self,\n    ctx: Context,\n    ev: ProductPersonalizationCompletedEvent | InventoryCompletedEvent | ReviewsCompletedEvent,\n) -&gt; StopEvent:\n</code></pre> <p>What this does:</p> <p>These changes integrate the Reviews Agent into the multi-agent workflow, allowing it to be triggered, run, and its results to be handled like other agents.</p> <p>Further Explanation:</p> <p>In this step, we explain how the Reviews Agent is integrated within the LlamaIndex workflow system. According to the LlamaIndex Workflows documentation, a workflow is an event-driven abstraction that chains together several steps, each responsible for handling specific event types and emitting new events.</p> <p>Here's how the code in this step leverages LlamaIndex workflows:</p> <ul> <li>The <code>MultiAgentFlow</code> class is structured as a workflow, where each function decorated with <code>@step</code> represents a step in the workflow. Each step listens for certain event types (like <code>ReviewsEvent</code>) and produces new events (like <code>ReviewsCompletedEvent</code>).</li> <li>By adding the Reviews Agent, we introduce a new step (<code>review</code>) that is triggered when a <code>ReviewsEvent</code> is emitted. This step processes the event, runs the Reviews Agent, and emits a <code>ReviewsCompletedEvent</code> with the result.</li> <li>The workflow system ensures that each step only runs when the appropriate event is ready, and the input/output types are validated automatically.</li> <li>This modular, event-driven approach allows you to flexibly chain together multiple agents and logic, making it easy to extend or modify the workflow as your application grows.</li> </ul> <p>In summary, this step connects the Reviews Agent to the overall multi-agent workflow, enabling event-driven, modular, and observable orchestration of agent logic using LlamaIndex's workflow system.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/06-workflow-service-integration/","title":"5.6: Workflow Service Integration","text":"<p>This section provides an overview of how the Reviews Agent is initialized and included in the workflow service (<code>backend/src/services/agent_workflow.py</code>). The agent is imported and passed to the <code>MultiAgentFlow</code> during initialization, ensuring it is part of the overall multi-agent orchestration.</p> <p>File location: <code>backend/src/services/agent_workflow.py</code></p> <p>Purpose: This integration wires the Reviews Agent into the workflow service, so it can be used as part of the multi-agent system.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/06-workflow-service-integration/#reviews-agent-import","title":"Reviews Agent Import","text":"<p>The <code>get_reviews_agent</code> function is imported alongside other agent constructors:</p> Python<pre><code>from src.agents import (\n    get_inventory_agent,\n    get_planning_agent,\n    get_presentation_agent,\n    get_product_personalization_agent,\n    get_reviews_agent,\n)\n</code></pre>"},{"location":"05-Agent%20Architecture%20and%20Integration/06-workflow-service-integration/#passing-reviews-agent-to-multiagentflow","title":"Passing Reviews Agent to MultiAgentFlow","text":"<p>The Reviews Agent is passed as an argument when initializing the <code>MultiAgentFlow</code> in the <code>create_workflow</code> function:</p> Python<pre><code>reviews_agent=get_reviews_agent(\n    self.llm,\n    self.embed_model,\n    self.vector_store_reviews_embeddings,\n    self.filters,\n),\n</code></pre> <p>The full initialization looks like this:</p> Python<pre><code>def create_workflow(self) -&gt; MultiAgentFlow:\n    workflow = MultiAgentFlow(\n        self.db,\n        product_personalization_agent=get_product_personalization_agent(self.llm),\n        presentation_agent=get_presentation_agent(self.llm),\n        inventory_agent=get_inventory_agent(\n            self.llm,\n            self.embed_model,\n        ),\n        planning_agent=get_planning_agent(self.llm),\n        reviews_agent=get_reviews_agent(\n            self.llm,\n            self.embed_model,\n            self.vector_store_reviews_embeddings,\n            self.filters,\n        ),\n        memory=self.memory,\n        message_queue=self.message_queue,\n        timeout=self.timeout,\n        verbose=self.verbose,\n        fault_correction=self.fault_correction,\n    )\n    return workflow\n</code></pre> <p>What this does:</p> <p>This ensures the Reviews Agent is properly initialized and included in the workflow service.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/07-agent-timeout-configuraion/","title":"5.7: Agent Timeout Configuration","text":"<p>This section provides an overview of the <code>REVIEW_AGENT_TIMEOUT</code> setting in <code>backend/src/config/config.py</code>. This configuration sets the maximum amount of time the Reviews Agent will take to process a request, after which it will timeout, allowing the agentic flow to move forward gracefully.</p> <p>File location: <code>backend/src/config/config.py</code></p> <p>Purpose: This configuration ensures the Reviews Agent has a timeout, allowing it to exit gracefully if a request takes too long.</p> <p>The timeout is set as a class variable in the settings class:</p> Python<pre><code>REVIEW_AGENT_TIMEOUT: int = 60\n</code></pre> <p>What this does:</p> <p>This ensures the Reviews Agent has a proper timeout configuration, allowing it to timeout gracefully without disrupting the rest of the agentic flow.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/08-running-multi-agent-flow/","title":"5.8 Multi-Agent Workflow Execution","text":"<p>This section provides an overview of how the multi-agent workflow operates with the integrated Reviews Agent. Here, you'll see how the system responds to user queries, how the Reviews Agent is triggered, and how its output is incorporated into the overall response.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/08-running-multi-agent-flow/#triggering-the-workflow","title":"Triggering the Workflow","text":"<p>When a user enters a natural language query such as:</p> Text Only<pre><code>Show summary of critical reviews about durability\n</code></pre> <p>the workflow processes the request and activates the Reviews Agent to generate a summary of relevant product reviews.</p> <p></p>"},{"location":"05-Agent%20Architecture%20and%20Integration/08-running-multi-agent-flow/#output-and-visualization","title":"Output and Visualization","text":"<p>After processing, the summary generated by the Reviews Agent appears in the personalized section of the product page:</p> <p></p> <p>You can also confirm the execution of the Reviews Agent by viewing the workflow debug flow diagram in the side panel. The diagram will show the Reviews Agent as part of the flow, indicating it was triggered and contributed to the response:</p> <p></p> <p>Congratulations! \ud83c\udf89 You've successfully run and verified the multi-agent workflow with the Reviews Agent. This is a crucial skill for building, testing, and debugging intelligent agent systems in real-world applications.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/","title":"5.9 Evaluation Agent","text":"<p>Our Agentic Workflow includes an Evaluation Agent that reviews the outputs of other agents to catch any faulty or inappropriate information before it reaches the final response. If a discrepancy is detected, the Evaluation Agent automatically retriggers the agent to generate a corrected output.  </p> <p>In this guide, the flow has been set up specifically for the Review Agent. To illustrate the self-correction mechanism, the guide mocks invalid output by intentionally adding irrelevant information to the Review Agent\u2019s response. The Evaluation Agent then detects this faulty output and automatically retriggers the Review Agent to produce a revised, corrected response.  </p> <p>The Evaluation Agent is activated when you toggle Enable Self Correction from the frontend Agentic Flow panel. Once enabled, you\u2019ll see how the workflow detects the mocked invalid output, retriggers the Review Agent, and ensures that only user-appropriate information makes it into the final workflow results.  </p> <p>Let\u2019s walk through the details and see an example of the Evaluation Agent in action.</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/#implementation-guide-evaluation-agent","title":"Implementation Guide: Evaluation Agent","text":"<p>The Evaluation Agent is designed to safeguard the workflow by reviewing agent outputs and preventing any sensitive backend details (such as internal database IDs) from being exposed to end users. Here\u2019s how it is implemented step by step:</p>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/#1-defining-the-evaluation-prompt","title":"1. Defining the Evaluation Prompt","text":"<p>File: <code>src/agents/prompts.py</code></p> Python<pre><code>Your task is to analyze the output of different agents and make sure that no internal database ID's are being\nextracted or passed to the user.\n\nIn case the data contains any internal ID's, just output \"retrigger\" followed by a short but descriptive error message.\nIn case the data doesn't contain any internal ID's, just output \"ok\".\n</code></pre> <p>This prompt enforces strict rules:  </p> <ul> <li>If an internal ID is detected \u2192 respond with <code>retrigger</code> and an error message.  </li> <li>Otherwise \u2192 respond with <code>ok</code>.  </li> </ul>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/#2-creating-the-evaluation-agent","title":"2. Creating the Evaluation Agent","text":"<p>File: <code>src/agents/evaluation_agent.py</code></p> Python<pre><code>def get_evaluation_agent(llm: BaseLLM):\n    return FunctionAgent(\n        name=AgentNames.EVALUATION_AGENT.value,\n        description=(\n            \"Reviews agent outputs to ensure internal database identifiers are not exposed to end users. \"\n            \"Acts as a safeguard to maintain data integrity and prevent leakage of backend-specific details.\"\n        ),\n        llm=llm,\n        system_prompt=EVALUATION_PROMPT,\n        tools=[],\n        verbose=settings.VERBOSE,\n        allow_parallel_tool_calls=False,\n    )\n</code></pre> <p>This defines the Evaluation Agent with:  </p> <ul> <li>No tools (pure review role).  </li> <li>A system prompt based on the evaluation rules above.  </li> <li>A descriptive name and purpose to make logs and traces more interpretable.  </li> </ul>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/#3-adding-the-evaluation-step","title":"3. Adding the Evaluation Step","text":"<p>File: <code>src/workflows/multi_agent_workflow.py</code></p> Python<pre><code>@step\nasync def evaluate_output(\n    self,\n    ctx: Context,\n    ev: EvaluationEvent,\n) -&gt; ReviewsCompletedEvent | ReviewsEvent:\n\n    agent_output = ev.result\n\n    try:\n        result = await self.evaluation_agent.run(\n            f\"Review the following output: output={agent_output}\",\n        )\n\n        logger.info(\"Evaluation Result: %s\", result)\n\n        if \"retrigger\" in str(result):\n            return ReviewsEvent(\n                self_reflection=str(result),\n                prev_result=agent_output,\n            )\n        else:\n            return ReviewsCompletedEvent(result=str(agent_output))\n\n    except WorkflowTimeoutError:\n        logger.info(\"Evaluation Agent has timed out.\")\n\n    return ReviewsCompletedEvent(result=str(agent_output))\n</code></pre> <p>This step:  </p> <ul> <li>Runs the Evaluation Agent on the Review Agent\u2019s output.  </li> <li>If the output contains internal IDs \u2192 triggers a new Review Agent run.  </li> <li>Otherwise \u2192 marks the review as complete.  </li> </ul>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/#4-mocking-faulty-output-for-demonstration","title":"4. Mocking Faulty Output for Demonstration","text":"<p>To showcase fault detection in the workshop, we intentionally inject errors when <code>Enable Fault Correction</code> is toggled on in the frontend.  </p> <p>File: <code>src/workflows/multi_agent_workflow.py</code></p> Python<pre><code>if self.fault_correction and not ev.self_reflection:\n    # To mock faulty output...\n    # Only do this if fault_correction is enabled\n    # and this is the first run of the review agent\n    generate_error_prompt = \"\\n\\nIMPORTANT: Add some internal review_ids in the review_summary section as references.\"\n</code></pre> <p>Here we deliberately instruct the Review Agent to insert invalid <code>review_ids</code> into its output, simulating a failure case.  </p>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/#5-routing-to-the-evaluation-step","title":"5. Routing to the Evaluation Step","text":"<p>Still within the Review step, the output is passed along:  </p> Python<pre><code>if self.fault_correction:\n    return EvaluationEvent(result=str(result))\nelse:\n    return ReviewsCompletedEvent(result=str(result))\n</code></pre> <p>This ensures:  </p> <ul> <li>When fault correction is enabled \u2192 the flow routes to the Evaluation Agent.  </li> <li>Otherwise \u2192 it completes normally.  </li> </ul>"},{"location":"05-Agent%20Architecture%20and%20Integration/09-evaluation-agent/#example","title":"Example","text":"<p>Let's go through an example run and see the Evaluation Agent in action.</p> <ul> <li> <p>Go to the product details page of a product, click <code>Agentic Flow</code> on the top right, toggle <code>Enable Self Corretion</code> and click Apply.</p> <p></p> <p>The workflow will be retriggered.</p> </li> <li> <p>Once completed, click on <code>Agentic Flow</code>. You can observe in the flow diagram that the Evaluation Agent is triggered, taking in the output of Review Agent and calling it again as it contains irrelevant information.</p> <p></p> </li> <li> <p>In <code>Review Agent(1)</code> tab we can observe that initially Review Agent output had irrelevant information.      </p> </li> <li> <p><code>Evaluation Agent(1)</code> shows that the evaluation agent takes in the agents responses and outputs the incorrect information that is present.     </p> </li> <li> <p>In <code>Review Agent(2)</code> tab we can observe that Review Agent generates the correct output when triggered again.     </p> </li> <li> <p>Finally in <code>Evaluation Agent(2)</code> we can see that the evaluation agent verifies that now the output doesnt contain the irrelevant information      </p> </li> </ul> <p>With this the Evaluation Agent helps ensure that only clean, user-appropriate information is presented, making the multi-agent workflow more robust and reliable.</p>"},{"location":"Tear%20Down/teardown/","title":"Cleanup Resources","text":""},{"location":"Tear%20Down/teardown/#clean-up","title":"Clean-up","text":"<p>Once you have completed this guide, delete the Azure resources you created. You are charged for the configured capacity and resource usage. Follow these instructions to delete your resource group and all resources you created for this solution accelerator.</p> <ol> <li> <p>In the VS Code integrated terminal, navigate to the root directory of your repository, execute the following command to delete the resources created by the <code>azd</code> workflow:</p> <p>Execute the following Azure Developer CLI command to delete resources!</p> <pre><code>azd down --purge\n</code></pre> <p>The <code>--purge</code> flag purges the resources that provide soft-delete functionality in Azure, including Azure KeyVault and Azure OpenAI. This flag is required to remove all resources completely.</p> </li> <li> <p>You will be shown a list of the resources that will be deleted and prompted about continuing. Enter \"y\" at the prompt to begin the resource deletion. When the tear down is completed, you shall see a <code>SUCCESS: Your application was removed from Azure in xx minutes xx seconds.</code> message at the end.</p> <p></p> </li> </ol>"},{"location":"Tear%20Down/teardown/#give-us-a-on-github","title":"Give us a \u2b50\ufe0f on GitHub","text":"<p>FOUND THIS GUIDE AND SAMPLE USEFUL? MAKE SURE YOU GET UPDATES.</p> <p>The Postgres Agentic Shop sample is an actively updated project that will reflect the latest features and best practices for code-first development of multi-agent workflows on the Azure AI platform. Visit the repo or click the button below, to give us a \u2b50\ufe0f.</p>"},{"location":"Tear%20Down/teardown/#provide-feedback","title":"Provide Feedback","text":"<p>Have feedback that can help us make this lab better for others? Open an issue and let us know.</p>"}]}